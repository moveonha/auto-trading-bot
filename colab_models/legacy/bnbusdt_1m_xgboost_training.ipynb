{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udd16 BNBUSDT 1m XGBOOST \ubaa8\ub378 \ud6c8\ub828\n",
        "## \uc554\ud638\ud654\ud3d0 \ud2b8\ub808\uc774\ub529 \uc2e0\ud638 \ucd5c\uc801\ud654\n",
        "- \uc2ec\ubcfc: BNBUSDT\n",
        "- \ud0c0\uc784\ud504\ub808\uc784: 1m\n",
        "- \ubaa8\ub378: XGBOOST\n",
        "- \uc0dd\uc131 \uc2dc\uac04: 2025-08-29 15:53:31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udce6 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \uc124\uce58\n",
        "%pip install pandas==2.0.3 numpy==1.24.3 scikit-learn==1.1.2 xgboost==2.1.4 lightgbm==4.6.0 tensorflow==2.13.0 pandas-ta==0.3.14b0 supabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd27 \ub77c\uc774\ube0c\ub7ec\ub9ac \uc784\ud3ec\ud2b8\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_ta as ta\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from supabase import create_client\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('\u2705 \ub77c\uc774\ube0c\ub7ec\ub9ac \ub85c\ub4dc \uc644\ub8cc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd11 Supabase \uc5f0\uacb0 \uc124\uc815\n",
        "SUPABASE_URL = 'https://yyvnfhezxkufzqdbqdni.supabase.co'\n",
        "SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inl5dm5maGV6eGt1ZnpxZGJxZG5pIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTY0MzMzODgsImV4cCI6MjA3MjAwOTM4OH0.4J9nwFo27szlzY8M1aMxs1UlDlGYmucGnD5u5P-UFBY'\n",
        "\n",
        "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "print('\u2705 Supabase \uc5f0\uacb0 \uc644\ub8cc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca \ub370\uc774\ud130 \uc218\uc9d1\n",
        "symbol = 'bnbusdt'\n",
        "timeframe = '1m'\n",
        "data_limit = 3000\n",
        "\n",
        "response = supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol.upper()).eq('timeframe', timeframe).order('timestamp', desc=True).limit(data_limit).execute()\n",
        "\n",
        "if response.data:\n",
        "    df = pd.DataFrame(response.data)\n",
        "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    df = df.sort_values('datetime')\n",
        "    print(f'\u2705 \ub370\uc774\ud130 \uc218\uc9d1 \uc644\ub8cc: {len(df)}\uac1c')\n",
        "    print(f'\ud83d\udcc5 \uae30\uac04: {{df[\"datetime\"].min()}} ~ {{df[\"datetime\"].max()}}')\n",
        "else:\n",
        "    print('\u274c \ub370\uc774\ud130\uac00 \uc5c6\uc2b5\ub2c8\ub2e4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83e\uddee \uace0\uae09 \uae30\uc220\uc801 \uc9c0\ud45c \uacc4\uc0b0\n",
        "def calculate_advanced_features(df):\n",
        "    # \uae30\ubcf8 \uc9c0\ud45c\ub4e4\n",
        "    df['sma_5'] = ta.sma(df['close'], length=5)\n",
        "    df['sma_10'] = ta.sma(df['close'], length=10)\n",
        "    df['sma_20'] = ta.sma(df['close'], length=20)\n",
        "    df['ema_9'] = ta.ema(df['close'], length=9)\n",
        "    df['ema_21'] = ta.ema(df['close'], length=21)\n",
        "    \n",
        "    # MACD\n",
        "    macd = ta.macd(df['close'], fast=6, slow=13, signal=4)\n",
        "    df['macd'] = macd['MACD_6_13_4']\n",
        "    df['macd_signal'] = macd['MACDs_6_13_4']\n",
        "    df['macd_histogram'] = macd['MACDh_6_13_4']\n",
        "    \n",
        "    # RSI\n",
        "    df['rsi'] = ta.rsi(df['close'], length=9)\n",
        "    df['rsi_14'] = ta.rsi(df['close'], length=14)\n",
        "    \n",
        "    # \ubcfc\ub9b0\uc800 \ubc34\ub4dc\n",
        "    bb = ta.bbands(df['close'], length=10, std=2)\n",
        "    df['bb_upper'] = bb['BBU_10_2.0']\n",
        "    df['bb_lower'] = bb['BBL_10_2.0']\n",
        "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']\n",
        "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
        "    \n",
        "    # \uc2a4\ud1a0\uce90\uc2a4\ud2f1\n",
        "    stoch = ta.stoch(df['high'], df['low'], df['close'], k=5, d=3)\n",
        "    df['stoch_k'] = stoch['STOCHk_5_3_3']\n",
        "    df['stoch_d'] = stoch['STOCHd_5_3_3']\n",
        "    \n",
        "    # ATR\n",
        "    df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=7)\n",
        "    df['atr_ratio'] = df['atr'] / df['close']\n",
        "    \n",
        "    # ADX\n",
        "    adx = ta.adx(df['high'], df['low'], df['close'], length=7)\n",
        "    df['adx'] = adx['ADX_7']\n",
        "    df['di_plus'] = adx['DMP_7']\n",
        "    df['di_minus'] = adx['DMN_7']\n",
        "    \n",
        "    # Williams %R\n",
        "    df['williams_r'] = ta.willr(df['high'], df['low'], df['close'], length=9)\n",
        "    \n",
        "    # Momentum\n",
        "    df['momentum'] = ta.mom(df['close'], length=10)\n",
        "    df['momentum_5'] = ta.mom(df['close'], length=5)\n",
        "    \n",
        "    # OBV\n",
        "    df['obv'] = ta.obv(df['close'], df['volume'])\n",
        "    df['obv_sma'] = ta.sma(df['obv'], length=20)\n",
        "    \n",
        "    # CCI\n",
        "    df['cci'] = ta.cci(df['high'], df['low'], df['close'], length=9)\n",
        "    \n",
        "    # Parabolic SAR\n",
        "    df['psar'] = ta.psar(df['high'], df['low'], df['close'])\n",
        "    \n",
        "    # \uac00\uaca9 \ubcc0\ud654\uc728\n",
        "    df['price_change'] = df['close'].pct_change()\n",
        "    df['price_change_5'] = df['close'].pct_change(5)\n",
        "    df['price_change_10'] = df['close'].pct_change(10)\n",
        "    \n",
        "    # \ubcfc\ub968 \uc9c0\ud45c\n",
        "    df['volume_sma'] = ta.sma(df['volume'], length=20)\n",
        "    df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
        "    \n",
        "    # \ubcc0\ub3d9\uc131 \uc9c0\ud45c\n",
        "    df['volatility'] = df['close'].rolling(20).std()\n",
        "    df['volatility_ratio'] = df['volatility'] / df['close']\n",
        "    \n",
        "    # \ucd94\uc138 \uc9c0\ud45c\n",
        "    df['trend_strength'] = abs(df['ema_9'] - df['ema_21']) / df['close']\n",
        "    df['trend_direction'] = np.where(df['ema_9'] > df['ema_21'], 1, -1)\n",
        "    \n",
        "    # \ud06c\ub85c\uc2a4\uc624\ubc84 \uc9c0\ud45c\n",
        "    df['ema_cross'] = np.where(df['ema_9'] > df['ema_21'], 1, 0)\n",
        "    df['ema_cross_change'] = df['ema_cross'].diff()\n",
        "    \n",
        "    df['macd_cross'] = np.where(df['macd'] > df['macd_signal'], 1, 0)\n",
        "    df['macd_cross_change'] = df['macd_cross'].diff()\n",
        "    \n",
        "    # \uc2dc\uac04 \uae30\ubc18 \ud2b9\uc131\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# \uc9c0\ud45c \uacc4\uc0b0\n",
        "df = calculate_advanced_features(df)\n",
        "print('\u2705 \uace0\uae09 \uc9c0\ud45c \uacc4\uc0b0 \uc644\ub8cc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83c\udfaf \ubaa9\ud45c \ubcc0\uc218 \uc0dd\uc131\n",
        "def create_target_variable(df, lookforward=5):\n",
        "    # \ubbf8\ub798 \uac00\uaca9 \ubcc0\ud654\uc728 \uacc4\uc0b0\n",
        "    df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1\n",
        "    \n",
        "    # \ubaa9\ud45c \ubcc0\uc218 \uc0dd\uc131\n",
        "    df['target'] = np.where(df['future_return'] > 0.01, 1,  # 1% \uc774\uc0c1 \uc0c1\uc2b9 \uc2dc LONG\n",
        "                      np.where(df['future_return'] < -0.01, -1, 0))  # 1% \uc774\uc0c1 \ud558\ub77d \uc2dc SHORT\n",
        "    \n",
        "    # \uc2e0\ud638 \uac15\ub3c4 \uacc4\uc0b0\n",
        "    df['signal_strength'] = abs(df['future_return']) * 100\n",
        "    \n",
        "    return df\n",
        "\n",
        "# \ubaa9\ud45c \ubcc0\uc218 \uc0dd\uc131\n",
        "df = create_target_variable(df)\n",
        "print('\u2705 \ubaa9\ud45c \ubcc0\uc218 \uc0dd\uc131 \uc644\ub8cc')\n",
        "print(f'\ud83d\udcca \ud0c0\uac9f \ubd84\ud3ec:\\n{{df[\"target\"].value_counts()}}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd27 \ud2b9\uc131 \uc900\ube44\n",
        "feature_columns = [\n",
        "    'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',\n",
        "    'macd', 'macd_signal', 'macd_histogram',\n",
        "    'rsi', 'rsi_14',\n",
        "    'bb_upper', 'bb_lower', 'bb_width', 'bb_position',\n",
        "    'stoch_k', 'stoch_d',\n",
        "    'atr', 'atr_ratio',\n",
        "    'adx', 'di_plus', 'di_minus',\n",
        "    'williams_r', 'momentum', 'momentum_5',\n",
        "    'obv', 'obv_sma', 'cci', 'psar',\n",
        "    'price_change', 'price_change_5', 'price_change_10',\n",
        "    'volume_ratio', 'volatility_ratio',\n",
        "    'trend_strength', 'trend_direction',\n",
        "    'ema_cross', 'ema_cross_change',\n",
        "    'macd_cross', 'macd_cross_change',\n",
        "    'hour', 'day_of_week', 'is_weekend'\n",
        "]\n",
        "\n",
        "# NaN \uac12 \ucc98\ub9ac\n",
        "df = df.dropna()\n",
        "\n",
        "# \ud2b9\uc131\uacfc \ud0c0\uac9f \ubd84\ub9ac\n",
        "X = df[feature_columns]\n",
        "y = df['target']\n",
        "\n",
        "print(f'\u2705 \ud2b9\uc131 \uc900\ube44 \uc644\ub8cc: {len(feature_columns)}\uac1c \ud2b9\uc131')\n",
        "print(f'\ud83d\udcca \ub370\uc774\ud130 \ud06c\uae30: {X.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83c\udfaf \ubaa8\ub378 \ud6c8\ub828\n",
        "model_type = 'xgboost'\n",
        "\n",
        "# \ub370\uc774\ud130 \ubd84\ud560\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# \ud2b9\uc131 \uc2a4\ucf00\uc77c\ub9c1\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# \ub77c\ubca8 \uc778\ucf54\ub529\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "print('\u2705 \ub370\uc774\ud130 \uc804\ucc98\ub9ac \uc644\ub8cc')\n",
        "\n",
        "# \ubaa8\ub378 \uc120\ud0dd \ubc0f \ud6c8\ub828\n",
        "if model_type == 'random_forest':\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "elif model_type == 'xgboost':\n",
        "    model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "elif model_type == 'lightgbm':\n",
        "    model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
        "elif model_type == 'lstm':\n",
        "    # LSTM \ubaa8\ub378\uc740 \ubcc4\ub3c4 \ucc98\ub9ac\n",
        "    pass\n",
        "else:\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "if model_type != 'lstm':\n",
        "    # \ubaa8\ub378 \ud6c8\ub828\n",
        "    model.fit(X_train_scaled, y_train_encoded)\n",
        "    \n",
        "    # \uc608\uce21\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    \n",
        "    print(f'\u2705 {model_type.upper()} \ubaa8\ub378 \ud6c8\ub828 \uc644\ub8cc')\n",
        "    print(f'\ud83d\udcca \uc815\ud655\ub3c4: {accuracy:.4f}')\n",
        "    \n",
        "    # \uad50\ucc28 \uac80\uc99d\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train_encoded, cv=5)\n",
        "    print(f'\ud83d\udcca \uad50\ucc28 \uac80\uc99d \ud3c9\uade0: {cv_scores.mean():.4f} (\u00b1{cv_scores.std():.4f})')\n",
        "    \n",
        "    # \ubd84\ub958 \ub9ac\ud3ec\ud2b8\n",
        "    print('\\n\ud83d\udccb \ubd84\ub958 \ub9ac\ud3ec\ud2b8:')\n",
        "    print(classification_report(y_test_encoded, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83e\udde0 LSTM \ubaa8\ub378 \ud6c8\ub828 (LSTM\uc778 \uacbd\uc6b0)\n",
        "if model_type == 'lstm':\n",
        "    sequence_length = 60\n",
        "    \n",
        "    # \uc2dc\uacc4\uc5f4 \ub370\uc774\ud130\ub85c \ubcc0\ud658\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "    \n",
        "    for i in range(sequence_length, len(X)):\n",
        "        X_sequences.append(X.iloc[i-sequence_length:i].values)\n",
        "        y_sequences.append(y.iloc[i])\n",
        "    \n",
        "    X_sequences = np.array(X_sequences)\n",
        "    y_sequences = np.array(y_sequences)\n",
        "    \n",
        "    # \ub370\uc774\ud130 \ubd84\ud560\n",
        "    split_idx = int(len(X_sequences) * 0.8)\n",
        "    X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:]\n",
        "    y_train, y_test = y_sequences[:split_idx], y_sequences[split_idx:]\n",
        "    \n",
        "    # \ud2b9\uc131 \uc2a4\ucf00\uc77c\ub9c1\n",
        "    scaler = StandardScaler()\n",
        "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
        "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
        "    \n",
        "    X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "    X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "    \n",
        "    X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
        "    X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
        "    \n",
        "    # \ub77c\ubca8 \uc778\ucf54\ub529\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "    \n",
        "    # \uc6d0-\ud56b \uc778\ucf54\ub529\n",
        "    y_train_onehot = tf.keras.utils.to_categorical(y_train_encoded, num_classes=3)\n",
        "    y_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=3)\n",
        "    \n",
        "    # LSTM \ubaa8\ub378 \uad6c\ucd95\n",
        "    model = Sequential([\n",
        "        LSTM(128, return_sequences=True, input_shape=(sequence_length, len(feature_columns))),\n",
        "        Dropout(0.2),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # \ucf5c\ubc31 \uc124\uc815\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "    ]\n",
        "    \n",
        "    # \ubaa8\ub378 \ud6c8\ub828\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train_onehot,\n",
        "        validation_data=(X_test_scaled, y_test_onehot),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # \ubaa8\ub378 \ud3c9\uac00\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
        "    \n",
        "    print(f'\u2705 LSTM \ubaa8\ub378 \ud6c8\ub828 \uc644\ub8cc')\n",
        "    print(f'\ud83d\udcca \uc815\ud655\ub3c4: {accuracy:.4f}')\n",
        "    \n",
        "    # \ubd84\ub958 \ub9ac\ud3ec\ud2b8\n",
        "    print('\\n\ud83d\udccb \ubd84\ub958 \ub9ac\ud3ec\ud2b8:')\n",
        "    print(classification_report(y_test_encoded, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcbe \ubaa8\ub378 \uc800\uc7a5\n",
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# \ubaa8\ub378 \ud30c\uc77c\uba85\n",
        "model_filename = f'{bnbusdt}_{1m}_{xgboost}_model'\n",
        "\n",
        "if model_type == 'lstm':\n",
        "    # LSTM \ubaa8\ub378 \uc800\uc7a5\n",
        "    model.save(f'{model_filename}.h5')\n",
        "    joblib.dump(scaler, f'{model_filename}_scaler.pkl')\n",
        "    joblib.dump(label_encoder, f'{model_filename}_encoder.pkl')\n",
        "    \n",
        "    # \ud30c\uc77c \ub2e4\uc6b4\ub85c\ub4dc\n",
        "    files.download(f'{model_filename}.h5')\n",
        "    files.download(f'{model_filename}_scaler.pkl')\n",
        "    files.download(f'{model_filename}_encoder.pkl')\n",
        "else:\n",
        "    # \uc77c\ubc18 \ubaa8\ub378 \uc800\uc7a5\n",
        "    joblib.dump(model, f'{model_filename}.pkl')\n",
        "    joblib.dump(scaler, f'{model_filename}_scaler.pkl')\n",
        "    joblib.dump(label_encoder, f'{model_filename}_encoder.pkl')\n",
        "    \n",
        "    # \ud30c\uc77c \ub2e4\uc6b4\ub85c\ub4dc\n",
        "    files.download(f'{model_filename}.pkl')\n",
        "    files.download(f'{model_filename}_scaler.pkl')\n",
        "    files.download(f'{model_filename}_encoder.pkl')\n",
        "\n",
        "print('\u2705 \ubaa8\ub378 \uc800\uc7a5 \ubc0f \ub2e4\uc6b4\ub85c\ub4dc \uc644\ub8cc')\n",
        "print(f'\ud83d\udcc1 \uc800\uc7a5\ub41c \ud30c\uc77c: {model_filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca \ud6c8\ub828 \uacb0\uacfc \uc694\uc57d\n",
        "print('\ud83c\udf89 \ud6c8\ub828 \uc644\ub8cc!')\n",
        "print(f'\ud83d\udcc8 \uc2ec\ubcfc: {symbol.upper()}')\n",
        "print(f'\u23f0 \ud0c0\uc784\ud504\ub808\uc784: {1m}')\n",
        "print(f'\ud83e\udd16 \ubaa8\ub378: {model_type.upper()}')\n",
        "print(f'\ud83d\udcca \ub370\uc774\ud130 \ud06c\uae30: {len(df)}\uac1c')\n",
        "print(f'\ud83d\udd27 \ud2b9\uc131 \uc218: {len(feature_columns)}\uac1c')\n",
        "\n",
        "if model_type != 'lstm':\n",
        "    print(f'\ud83c\udfaf \uc815\ud655\ub3c4: {accuracy:.4f}')\n",
        "    print(f'\ud83d\udcca \uad50\ucc28 \uac80\uc99d: {cv_scores.mean():.4f} (\u00b1{cv_scores.std():.4f})')\n",
        "else:\n",
        "    print(f'\ud83c\udfaf \uc815\ud655\ub3c4: {accuracy:.4f}')\n",
        "\n",
        "print('\\n\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4:')\n",
        "print('1. \ub2e4\uc6b4\ub85c\ub4dc\ub41c \ubaa8\ub378 \ud30c\uc77c\uc744 \ub85c\uceec\ub85c \uc774\ub3d9')\n",
        "print('2. \uc2e4\uc2dc\uac04 \ud2b8\ub808\uc774\ub529 \uc2dc\uc2a4\ud15c\uc5d0 \ubaa8\ub378 \ub85c\ub4dc')\n",
        "print('3. \ubc31\ud14c\uc2a4\ud305\uc73c\ub85c \uc131\ub2a5 \uac80\uc99d')\n",
        "print('4. \uc2e4\uc2dc\uac04 \uc2e0\ud638 \uc0dd\uc131 \uc2dc\uc791')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}