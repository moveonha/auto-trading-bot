import os
import json
import asyncio
import websockets
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from supabase import create_client
import pandas_ta as ta
import time
import logging
import pickle
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
import lightgbm as lgb
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ml_trading.log'),
        logging.StreamHandler()
    ]
)

class MLTradingOptimizer:
    def __init__(self):
        self.load_env_file()
        self.supabase = self.get_supabase_client()
        self.websocket = None
        self.is_running = False
        
        # ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥ì†Œ
        self.realtime_data = {}
        self.signal_history = []
        self.trade_history = []
        
        # ìˆ˜ì§‘í•  ì‹¬ë³¼ê³¼ íƒ€ì„í”„ë ˆì„
        self.symbols = ['btcusdt', 'ethusdt', 'bnbusdt', 'adausdt', 'solusdt']
        self.timeframes = ['1m', '5m', '15m', '1h']
        
        # ML ëª¨ë¸ë“¤
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.feature_columns = []
        
        # ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
        self.optimized_params = {
            'signal_threshold': 2.5,
            'position_size': 0.02,  # ê³„ì¢Œì˜ 2%
            'stop_loss_atr': 1.5,
            'take_profit_atr': 3.0,
            'max_holding_time': 24,  # ì‹œê°„
            'min_confidence': 0.7
        }
        
        # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼
        self.backtest_results = {}
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_path = Path('models')
        self.model_path.mkdir(exist_ok=True)
        
    def load_env_file(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        config_file = Path('.env')
        if not config_file.exists():
            raise FileNotFoundError(".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with open(config_file, 'r') as f:
            for line in f:
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value
    
    def get_supabase_client(self):
        """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        if not url or not key:
            raise ValueError("Supabase URL ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return create_client(url, key)
    
    def get_historical_data(self, symbol, timeframe, limit=1000):
        """ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # Supabaseì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            response = self.supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol.upper()).eq('timeframe', timeframe).order('timestamp', desc=True).limit(limit).execute()
            
            if response.data:
                df = pd.DataFrame(response.data)
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df.sort_values('datetime')
                return df
            else:
                logging.warning(f"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {symbol} {timeframe}")
                return None
                
        except Exception as e:
            logging.error(f"âŒ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def calculate_advanced_features(self, df):
        """ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì§€í‘œë“¤
            df['sma_5'] = ta.sma(df['close'], length=5)
            df['sma_10'] = ta.sma(df['close'], length=10)
            df['sma_20'] = ta.sma(df['close'], length=20)
            df['ema_9'] = ta.ema(df['close'], length=9)
            df['ema_21'] = ta.ema(df['close'], length=21)
            
            # MACD
            macd = ta.macd(df['close'], fast=6, slow=13, signal=4)
            df['macd'] = macd['MACD_6_13_4']
            df['macd_signal'] = macd['MACDs_6_13_4']
            df['macd_histogram'] = macd['MACDh_6_13_4']
            
            # RSI
            df['rsi'] = ta.rsi(df['close'], length=9)
            df['rsi_14'] = ta.rsi(df['close'], length=14)
            
            # ë³¼ë¦°ì € ë°´ë“œ
            bb = ta.bbands(df['close'], length=10, std=2)
            df['bb_upper'] = bb['BBU_10_2.0']
            df['bb_lower'] = bb['BBL_10_2.0']
            df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
            
            # ìŠ¤í† ìºìŠ¤í‹±
            stoch = ta.stoch(df['high'], df['low'], df['close'], k=5, d=3)
            df['stoch_k'] = stoch['STOCHk_5_3_3']
            df['stoch_d'] = stoch['STOCHd_5_3_3']
            
            # ATR
            df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=7)
            df['atr_ratio'] = df['atr'] / df['close']
            
            # ADX
            adx = ta.adx(df['high'], df['low'], df['close'], length=7)
            df['adx'] = adx['ADX_7']
            df['di_plus'] = adx['DMP_7']
            df['di_minus'] = adx['DMN_7']
            
            # Williams %R
            df['williams_r'] = ta.willr(df['high'], df['low'], df['close'], length=9)
            
            # Momentum
            df['momentum'] = ta.mom(df['close'], length=10)
            df['momentum_5'] = ta.mom(df['close'], length=5)
            
            # OBV (On Balance Volume)
            df['obv'] = ta.obv(df['close'], df['volume'])
            df['obv_sma'] = ta.sma(df['obv'], length=20)
            
            # CCI (Commodity Channel Index)
            df['cci'] = ta.cci(df['high'], df['low'], df['close'], length=9)
            
            # Parabolic SAR
            df['psar'] = ta.psar(df['high'], df['low'], df['close'])
            
            # ê°€ê²© ë³€í™”ìœ¨
            df['price_change'] = df['close'].pct_change()
            df['price_change_5'] = df['close'].pct_change(5)
            df['price_change_10'] = df['close'].pct_change(10)
            
            # ë³¼ë¥¨ ì§€í‘œ
            df['volume_sma'] = ta.sma(df['volume'], length=20)
            df['volume_ratio'] = df['volume'] / df['volume_sma']
            
            # ë³€ë™ì„± ì§€í‘œ
            df['volatility'] = df['close'].rolling(20).std()
            df['volatility_ratio'] = df['volatility'] / df['close']
            
            # ì¶”ì„¸ ì§€í‘œ
            df['trend_strength'] = abs(df['ema_9'] - df['ema_21']) / df['close']
            df['trend_direction'] = np.where(df['ema_9'] > df['ema_21'], 1, -1)
            
            # í¬ë¡œìŠ¤ì˜¤ë²„ ì§€í‘œ
            df['ema_cross'] = np.where(df['ema_9'] > df['ema_21'], 1, 0)
            df['ema_cross_change'] = df['ema_cross'].diff()
            
            df['macd_cross'] = np.where(df['macd'] > df['macd_signal'], 1, 0)
            df['macd_cross_change'] = df['macd_cross'].diff()
            
            # ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±
            df['hour'] = df['datetime'].dt.hour
            df['day_of_week'] = df['datetime'].dt.dayofweek
            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
            
            return df
            
        except Exception as e:
            logging.error(f"âŒ ê³ ê¸‰ ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return df
    
    def create_target_variable(self, df, lookforward=5):
        """ëª©í‘œ ë³€ìˆ˜ ìƒì„± (ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜)"""
        try:
            # ë¯¸ë˜ ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°
            df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1
            
            # ëª©í‘œ ë³€ìˆ˜ ìƒì„±
            df['target'] = np.where(df['future_return'] > 0.01, 1,  # 1% ì´ìƒ ìƒìŠ¹ ì‹œ LONG
                          np.where(df['future_return'] < -0.01, -1, 0))  # 1% ì´ìƒ í•˜ë½ ì‹œ SHORT
            
            # ì‹ í˜¸ ê°•ë„ ê³„ì‚°
            df['signal_strength'] = abs(df['future_return']) * 100
            
            return df
            
        except Exception as e:
            logging.error(f"âŒ ëª©í‘œ ë³€ìˆ˜ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return df
    
    def prepare_features(self, df):
        """íŠ¹ì„± ì¤€ë¹„"""
        try:
            # ì‚¬ìš©í•  íŠ¹ì„± ì»¬ëŸ¼ë“¤
            feature_columns = [
                'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',
                'macd', 'macd_signal', 'macd_histogram',
                'rsi', 'rsi_14',
                'bb_upper', 'bb_lower', 'bb_width', 'bb_position',
                'stoch_k', 'stoch_d',
                'atr', 'atr_ratio',
                'adx', 'di_plus', 'di_minus',
                'williams_r', 'momentum', 'momentum_5',
                'obv', 'obv_sma', 'cci', 'psar',
                'price_change', 'price_change_5', 'price_change_10',
                'volume_ratio', 'volatility_ratio',
                'trend_strength', 'trend_direction',
                'ema_cross', 'ema_cross_change',
                'macd_cross', 'macd_cross_change',
                'hour', 'day_of_week', 'is_weekend'
            ]
            
            # NaN ê°’ ì²˜ë¦¬
            df = df.dropna()
            
            # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
            X = df[feature_columns]
            y = df['target']
            
            return X, y, feature_columns
            
        except Exception as e:
            logging.error(f"âŒ íŠ¹ì„± ì¤€ë¹„ ì˜¤ë¥˜: {str(e)}")
            return None, None, None
    
    def train_models(self, symbol, timeframe):
        """ëª¨ë¸ í›ˆë ¨"""
        try:
            logging.info(f"ğŸ”„ {symbol} {timeframe} ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            
            # ë°ì´í„° ìˆ˜ì§‘
            df = self.get_historical_data(symbol, timeframe, limit=2000)
            if df is None or len(df) < 500:
                logging.warning(f"ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {symbol} {timeframe}")
                return False
            
            # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
            df = self.calculate_advanced_features(df)
            
            # ëª©í‘œ ë³€ìˆ˜ ìƒì„±
            df = self.create_target_variable(df)
            
            # íŠ¹ì„± ì¤€ë¹„
            X, y, feature_columns = self.prepare_features(df)
            if X is None:
                return False
            
            self.feature_columns = feature_columns
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
            
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ë¼ë²¨ ì¸ì½”ë”©
            label_encoder = LabelEncoder()
            y_train_encoded = label_encoder.fit_transform(y_train)
            y_test_encoded = label_encoder.transform(y_test)
            
            # ëª¨ë¸ë“¤ ì •ì˜
            models = {
                'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
                'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
                'xgboost': xgb.XGBClassifier(n_estimators=100, random_state=42),
                'lightgbm': lgb.LGBMClassifier(n_estimators=100, random_state=42),
                'mlp': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
            }
            
            # ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
            best_model = None
            best_score = 0
            
            for name, model in models.items():
                logging.info(f"í›ˆë ¨ ì¤‘: {name}")
                
                # í›ˆë ¨
                model.fit(X_train_scaled, y_train_encoded)
                
                # ì˜ˆì¸¡
                y_pred = model.predict(X_test_scaled)
                accuracy = accuracy_score(y_test_encoded, y_pred)
                
                logging.info(f"{name} ì •í™•ë„: {accuracy:.4f}")
                
                # êµì°¨ ê²€ì¦
                cv_scores = cross_val_score(model, X_train_scaled, y_train_encoded, cv=5)
                cv_mean = cv_scores.mean()
                logging.info(f"{name} êµì°¨ ê²€ì¦ í‰ê· : {cv_mean:.4f}")
                
                # ìµœê³  ëª¨ë¸ ì„ íƒ
                if cv_mean > best_score:
                    best_score = cv_mean
                    best_model = model
                    best_model_name = name
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            key = f"{symbol}_{timeframe}"
            self.models[key] = best_model
            self.scalers[key] = scaler
            self.label_encoders[key] = label_encoder
            
            # ëª¨ë¸ íŒŒì¼ ì €ì¥
            model_file = self.model_path / f"{key}_model.pkl"
            scaler_file = self.model_path / f"{key}_scaler.pkl"
            encoder_file = self.model_path / f"{key}_encoder.pkl"
            
            joblib.dump(best_model, model_file)
            joblib.dump(scaler, scaler_file)
            joblib.dump(label_encoder, encoder_file)
            
            logging.info(f"âœ… {symbol} {timeframe} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ìµœê³  ëª¨ë¸: {best_model_name} (ì •í™•ë„: {best_score:.4f})")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ ëª¨ë¸ í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def train_lstm_model(self, symbol, timeframe):
        """LSTM ëª¨ë¸ í›ˆë ¨"""
        try:
            logging.info(f"ğŸ”„ {symbol} {timeframe} LSTM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            
            # ë°ì´í„° ìˆ˜ì§‘
            df = self.get_historical_data(symbol, timeframe, limit=3000)
            if df is None or len(df) < 1000:
                return False
            
            # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
            df = self.calculate_advanced_features(df)
            df = self.create_target_variable(df)
            
            # íŠ¹ì„± ì¤€ë¹„
            X, y, feature_columns = self.prepare_features(df)
            if X is None:
                return False
            
            # ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë³€í™˜ (ì‹œí€€ìŠ¤ ê¸¸ì´: 60)
            sequence_length = 60
            X_sequences = []
            y_sequences = []
            
            for i in range(sequence_length, len(X)):
                X_sequences.append(X.iloc[i-sequence_length:i].values)
                y_sequences.append(y.iloc[i])
            
            X_sequences = np.array(X_sequences)
            y_sequences = np.array(y_sequences)
            
            # ë°ì´í„° ë¶„í• 
            split_idx = int(len(X_sequences) * 0.8)
            X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:]
            y_train, y_test = y_sequences[:split_idx], y_sequences[split_idx:]
            
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])
            X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])
            
            X_train_scaled = scaler.fit_transform(X_train_reshaped)
            X_test_scaled = scaler.transform(X_test_reshaped)
            
            X_train_scaled = X_train_scaled.reshape(X_train.shape)
            X_test_scaled = X_test_scaled.reshape(X_test.shape)
            
            # ë¼ë²¨ ì¸ì½”ë”©
            label_encoder = LabelEncoder()
            y_train_encoded = label_encoder.fit_transform(y_train)
            y_test_encoded = label_encoder.transform(y_test)
            
            # ì›-í•« ì¸ì½”ë”©
            y_train_onehot = tf.keras.utils.to_categorical(y_train_encoded, num_classes=3)
            y_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=3)
            
            # LSTM ëª¨ë¸ êµ¬ì¶•
            model = Sequential([
                LSTM(128, return_sequences=True, input_shape=(sequence_length, len(feature_columns))),
                Dropout(0.2),
                LSTM(64, return_sequences=False),
                Dropout(0.2),
                Dense(32, activation='relu'),
                Dropout(0.2),
                Dense(3, activation='softmax')
            ])
            
            model.compile(
                optimizer=Adam(learning_rate=0.001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
            
            # ì½œë°± ì„¤ì •
            callbacks = [
                EarlyStopping(patience=10, restore_best_weights=True),
                ReduceLROnPlateau(factor=0.5, patience=5)
            ]
            
            # ëª¨ë¸ í›ˆë ¨
            history = model.fit(
                X_train_scaled, y_train_onehot,
                validation_data=(X_test_scaled, y_test_onehot),
                epochs=100,
                batch_size=32,
                callbacks=callbacks,
                verbose=1
            )
            
            # ëª¨ë¸ í‰ê°€
            y_pred = model.predict(X_test_scaled)
            y_pred_classes = np.argmax(y_pred, axis=1)
            accuracy = accuracy_score(y_test_encoded, y_pred_classes)
            
            logging.info(f"LSTM ì •í™•ë„: {accuracy:.4f}")
            
            # ëª¨ë¸ ì €ì¥
            key = f"{symbol}_{timeframe}_lstm"
            self.models[key] = model
            self.scalers[key] = scaler
            self.label_encoders[key] = label_encoder
            
            model.save(self.model_path / f"{key}_model.h5")
            joblib.dump(scaler, self.model_path / f"{key}_scaler.pkl")
            joblib.dump(label_encoder, self.model_path / f"{key}_encoder.pkl")
            
            logging.info(f"âœ… {symbol} {timeframe} LSTM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ LSTM ëª¨ë¸ í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def predict_signal(self, symbol, timeframe, current_data):
        """ì‹¤ì‹œê°„ ì‹ í˜¸ ì˜ˆì¸¡"""
        try:
            key = f"{symbol}_{timeframe}"
            
            if key not in self.models:
                logging.warning(f"ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {key}")
                return None
            
            model = self.models[key]
            scaler = self.scalers[key]
            label_encoder = self.label_encoders[key]
            
            # íŠ¹ì„± ê³„ì‚°
            features = self.calculate_advanced_features(current_data)
            if features is None or len(features) < 50:
                return None
            
            # ìµœì‹  ë°ì´í„° ì¶”ì¶œ
            latest_features = features[self.feature_columns].iloc[-1:].values
            
            # ìŠ¤ì¼€ì¼ë§
            scaled_features = scaler.transform(latest_features)
            
            # ì˜ˆì¸¡
            if 'lstm' in key:
                # LSTM ëª¨ë¸ì˜ ê²½ìš° ì‹œí€€ìŠ¤ ë°ì´í„° í•„ìš”
                return None  # ì‹¤ì‹œê°„ LSTM ì˜ˆì¸¡ì€ ë³µì¡í•˜ë¯€ë¡œ ì¼ë‹¨ ì œì™¸
            else:
                prediction = model.predict(scaled_features)[0]
                probabilities = model.predict_proba(scaled_features)[0]
                
                # ì‹ í˜¸ ìƒì„±
                signal = {
                    'symbol': symbol.upper(),
                    'timeframe': timeframe,
                    'prediction': prediction,
                    'probabilities': probabilities,
                    'confidence': max(probabilities),
                    'action': label_encoder.inverse_transform([prediction])[0],
                    'datetime': datetime.now()
                }
                
                return signal
                
        except Exception as e:
            logging.error(f"âŒ ì‹ í˜¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def optimize_parameters(self, symbol, timeframe):
        """íŒŒë¼ë¯¸í„° ìµœì í™”"""
        try:
            logging.info(f"ğŸ”„ {symbol} {timeframe} íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")
            
            # ë°±í…ŒìŠ¤íŒ…ì„ í†µí•œ íŒŒë¼ë¯¸í„° ìµœì í™”
            best_params = self.optimized_params.copy()
            best_sharpe = -999
            
            # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            param_grid = {
                'signal_threshold': [1.5, 2.0, 2.5, 3.0, 3.5],
                'stop_loss_atr': [1.0, 1.5, 2.0, 2.5],
                'take_profit_atr': [2.0, 3.0, 4.0, 5.0],
                'min_confidence': [0.6, 0.7, 0.8, 0.9]
            }
            
            # ê·¸ë¦¬ë“œ ì„œì¹˜
            for threshold in param_grid['signal_threshold']:
                for stop_loss in param_grid['stop_loss_atr']:
                    for take_profit in param_grid['take_profit_atr']:
                        for confidence in param_grid['min_confidence']:
                            
                            params = {
                                'signal_threshold': threshold,
                                'stop_loss_atr': stop_loss,
                                'take_profit_atr': take_profit,
                                'min_confidence': confidence
                            }
                            
                            # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
                            results = self.run_backtest(symbol, timeframe, params)
                            
                            if results and results['sharpe_ratio'] > best_sharpe:
                                best_sharpe = results['sharpe_ratio']
                                best_params.update(params)
                                logging.info(f"ìƒˆë¡œìš´ ìµœê³  íŒŒë¼ë¯¸í„° ë°œê²¬! Sharpe: {best_sharpe:.4f}")
            
            self.optimized_params = best_params
            logging.info(f"âœ… íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ! ìµœê³  Sharpe: {best_sharpe:.4f}")
            
            return best_params
            
        except Exception as e:
            logging.error(f"âŒ íŒŒë¼ë¯¸í„° ìµœì í™” ì˜¤ë¥˜: {str(e)}")
            return self.optimized_params
    
    def run_backtest(self, symbol, timeframe, params=None):
        """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
        try:
            if params is None:
                params = self.optimized_params
            
            # ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
            df = self.get_historical_data(symbol, timeframe, limit=1000)
            if df is None:
                return None
            
            # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
            df = self.calculate_advanced_features(df)
            
            # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼
            trades = []
            position = None
            entry_price = 0
            entry_time = None
            
            for i in range(100, len(df)):
                current_data = df.iloc[:i+1]
                
                # ì‹ í˜¸ ì˜ˆì¸¡
                signal = self.predict_signal(symbol, timeframe, current_data)
                
                if signal is None:
                    continue
                
                current_price = df.iloc[i]['close']
                current_time = df.iloc[i]['datetime']
                
                # í¬ì§€ì…˜ ì§„ì… ì¡°ê±´
                if position is None and signal['confidence'] >= params['min_confidence']:
                    if signal['action'] in [1, -1]:  # LONG ë˜ëŠ” SHORT
                        position = signal['action']
                        entry_price = current_price
                        entry_time = current_time
                        
                        trades.append({
                            'entry_time': entry_time,
                            'entry_price': entry_price,
                            'position': 'LONG' if position == 1 else 'SHORT',
                            'confidence': signal['confidence']
                        })
                
                # í¬ì§€ì…˜ ì²­ì‚° ì¡°ê±´
                elif position is not None:
                    # ATR ê³„ì‚°
                    atr = df.iloc[i]['atr']
                    
                    # ì†ì ˆ/ìµì ˆ ê³„ì‚°
                    if position == 1:  # LONG
                        stop_loss = entry_price - (atr * params['stop_loss_atr'])
                        take_profit = entry_price + (atr * params['take_profit_atr'])
                        
                        if current_price <= stop_loss or current_price >= take_profit:
                            # ì²­ì‚°
                            exit_price = current_price
                            pnl = (exit_price - entry_price) / entry_price
                            
                            trades[-1].update({
                                'exit_time': current_time,
                                'exit_price': exit_price,
                                'pnl': pnl,
                                'exit_reason': 'stop_loss' if current_price <= stop_loss else 'take_profit'
                            })
                            
                            position = None
                    
                    elif position == -1:  # SHORT
                        stop_loss = entry_price + (atr * params['stop_loss_atr'])
                        take_profit = entry_price - (atr * params['take_profit_atr'])
                        
                        if current_price >= stop_loss or current_price <= take_profit:
                            # ì²­ì‚°
                            exit_price = current_price
                            pnl = (entry_price - exit_price) / entry_price
                            
                            trades[-1].update({
                                'exit_time': current_time,
                                'exit_price': exit_price,
                                'pnl': pnl,
                                'exit_reason': 'stop_loss' if current_price >= stop_loss else 'take_profit'
                            })
                            
                            position = None
                
                # ìµœëŒ€ ë³´ìœ  ì‹œê°„ ì²´í¬
                if position is not None and entry_time:
                    holding_time = (current_time - entry_time).total_seconds() / 3600
                    if holding_time > params.get('max_holding_time', 24):
                        # ê°•ì œ ì²­ì‚°
                        exit_price = current_price
                        if position == 1:
                            pnl = (exit_price - entry_price) / entry_price
                        else:
                            pnl = (entry_price - exit_price) / entry_price
                        
                        trades[-1].update({
                            'exit_time': current_time,
                            'exit_price': exit_price,
                            'pnl': pnl,
                            'exit_reason': 'timeout'
                        })
                        
                        position = None
            
            # ê²°ê³¼ ê³„ì‚°
            if not trades:
                return None
            
            completed_trades = [t for t in trades if 'exit_price' in t]
            
            if not completed_trades:
                return None
            
            total_return = sum(t['pnl'] for t in completed_trades)
            win_trades = [t for t in completed_trades if t['pnl'] > 0]
            win_rate = len(win_trades) / len(completed_trades)
            
            returns = [t['pnl'] for t in completed_trades]
            sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
            
            results = {
                'total_trades': len(completed_trades),
                'win_rate': win_rate,
                'total_return': total_return,
                'sharpe_ratio': sharpe_ratio,
                'avg_return': np.mean(returns),
                'max_drawdown': min(returns) if returns else 0,
                'trades': completed_trades
            }
            
            return results
            
        except Exception as e:
            logging.error(f"âŒ ë°±í…ŒìŠ¤íŒ… ì˜¤ë¥˜: {str(e)}")
            return None
    
    def train_all_models(self):
        """ëª¨ë“  ì‹¬ë³¼ê³¼ íƒ€ì„í”„ë ˆì„ì— ëŒ€í•´ ëª¨ë¸ í›ˆë ¨"""
        logging.info("ğŸš€ ì „ì²´ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        success_count = 0
        total_count = len(self.symbols) * len(self.timeframes)
        
        for symbol in self.symbols:
            for timeframe in self.timeframes:
                try:
                    # ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨
                    if self.train_models(symbol, timeframe):
                        success_count += 1
                    
                    # LSTM ëª¨ë¸ í›ˆë ¨
                    if self.train_lstm_model(symbol, timeframe):
                        success_count += 1
                    
                    # íŒŒë¼ë¯¸í„° ìµœì í™”
                    self.optimize_parameters(symbol, timeframe)
                    
                except Exception as e:
                    logging.error(f"âŒ {symbol} {timeframe} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
        
        logging.info(f"âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ì„±ê³µ: {success_count}/{total_count * 2}")
    
    def generate_ml_signals(self):
        """ML ê¸°ë°˜ ì‹¤ì‹œê°„ ì‹ í˜¸ ìƒì„±"""
        logging.info("ğŸ¤– ML ê¸°ë°˜ ì‹¤ì‹œê°„ ì‹ í˜¸ ìƒì„± ì‹œì‘...")
        
        while self.is_running:
            try:
                # ê° ì‹¬ë³¼ê³¼ íƒ€ì„í”„ë ˆì„ì— ëŒ€í•´ ì‹ í˜¸ ìƒì„±
                for symbol in self.symbols:
                    for timeframe in self.timeframes:
                        key = f"{symbol}_{timeframe}"
                        
                        if key in self.realtime_data and len(self.realtime_data[key]) > 50:
                            # ìµœì‹  ë°ì´í„°ë¡œ ì‹ í˜¸ ì˜ˆì¸¡
                            current_data = pd.DataFrame(self.realtime_data[key])
                            signal = self.predict_signal(symbol, timeframe, current_data)
                            
                            if signal and signal['confidence'] >= self.optimized_params['min_confidence']:
                                # ì‹ í˜¸ ì²˜ë¦¬
                                self.process_ml_signal(signal)
                
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì²´í¬
                
            except Exception as e:
                logging.error(f"âŒ ML ì‹ í˜¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                time.sleep(30)
    
    def process_ml_signal(self, signal):
        """ML ì‹ í˜¸ ì²˜ë¦¬"""
        try:
            action_emoji = "ğŸŸ¢" if signal['action'] == 1 else "ğŸ”´" if signal['action'] == -1 else "ğŸŸ¡"
            confidence_emoji = "ğŸ”¥" if signal['confidence'] >= 0.9 else "âš¡" if signal['confidence'] >= 0.8 else "ğŸ’¤"
            
            logging.info(f"ğŸ¤– {action_emoji} ML {signal['action']} {confidence_emoji} - {signal['symbol']} {signal['timeframe']}")
            logging.info(f"   ğŸ’° ì‹ ë¢°ë„: {signal['confidence']:.4f}")
            logging.info(f"   ğŸ“Š í™•ë¥ : {signal['probabilities']}")
            
            # ê°•í•œ ì‹ í˜¸ì¸ ê²½ìš° ì¦‰ì‹œ ì•Œë¦¼
            if signal['confidence'] >= 0.9:
                logging.warning(f"ğŸ”¥ ê°•í•œ ML ì‹ í˜¸ ê°ì§€! {signal['symbol']} {signal['timeframe']} {signal['action']}")
                
                # ì—¬ê¸°ì— ìë™ë§¤ë§¤ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                # await self.execute_ml_trade(signal)
            
        except Exception as e:
            logging.error(f"âŒ ML ì‹ í˜¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def start(self):
        """ML íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì‹œì‘"""
        self.is_running = True
        logging.info("ğŸ¤– ML ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì‹œì‘...")
        
        try:
            # ëª¨ë¸ í›ˆë ¨
            self.train_all_models()
            
            # ì‹¤ì‹œê°„ ì‹ í˜¸ ìƒì„± ì‹œì‘
            self.generate_ml_signals()
            
        except KeyboardInterrupt:
            logging.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logging.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        finally:
            self.stop()
    
    def stop(self):
        """ML íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.is_running = False
        logging.info("ML ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¤– ML ê¸°ë°˜ ì•”í˜¸í™”í íŠ¸ë ˆì´ë”© ìµœì í™” ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        ml_optimizer = MLTradingOptimizer()
        ml_optimizer.start()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
