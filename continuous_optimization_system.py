import os
import json
import asyncio
import time
import logging
import schedule
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd
import numpy as np
from supabase import create_client
import pandas_ta as ta
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('continuous_optimization.log'),
        logging.StreamHandler()
    ]
)

class ContinuousOptimizationSystem:
    def __init__(self):
        self.load_env_file()
        self.supabase = self.get_supabase_client()
        self.is_running = False
        
        # ìµœì í™” ì„¤ì •
        self.optimization_config = {
            'symbols': ['btcusdt', 'ethusdt', 'bnbusdt', 'adausdt', 'solusdt'],
            'timeframes': ['1m', '5m', '15m', '1h'],
            'models': ['random_forest', 'xgboost', 'lightgbm'],
            'data_limit': 3000,
            'retrain_interval_hours': 24,  # 24ì‹œê°„ë§ˆë‹¤ ì¬í›ˆë ¨
            'optimization_interval_hours': 6,  # 6ì‹œê°„ë§ˆë‹¤ íŒŒë¼ë¯¸í„° ìµœì í™”
            'backtest_days': 30,  # 30ì¼ ë°±í…ŒìŠ¤íŒ…
            'min_accuracy_threshold': 0.75,  # ìµœì†Œ ì •í™•ë„ ì„ê³„ê°’
            'min_sharpe_threshold': 1.0,  # ìµœì†Œ Sharpe Ratio ì„ê³„ê°’
            'max_drawdown_threshold': -0.1  # ìµœëŒ€ ì†ì‹¤ ì„ê³„ê°’
        }
        
        # ëª¨ë¸ ì €ì¥ì†Œ
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.feature_columns = []
        
        # ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
        self.optimized_params = {
            'signal_threshold': 2.5,
            'position_size': 0.02,
            'stop_loss_atr': 1.5,
            'take_profit_atr': 3.0,
            'max_holding_time': 24,
            'min_confidence': 0.7
        }
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = {}
        self.optimization_history = []
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_path = Path('optimized_models')
        self.model_path.mkdir(exist_ok=True)
        
        # ì„±ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤
        self.performance_db = Path('performance_data')
        self.performance_db.mkdir(exist_ok=True)
        
    def load_env_file(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        config_file = Path('.env')
        if not config_file.exists():
            raise FileNotFoundError(".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with open(config_file, 'r') as f:
            for line in f:
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value
    
    def get_supabase_client(self):
        """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        if not url or not key:
            raise ValueError("Supabase URL ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return create_client(url, key)
    
    def get_historical_data(self, symbol, timeframe, limit=1000):
        """ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            response = self.supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol.upper()).eq('timeframe', timeframe).order('timestamp', desc=True).limit(limit).execute()
            
            if response.data:
                df = pd.DataFrame(response.data)
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df.sort_values('datetime')
                return df
            else:
                logging.warning(f"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {symbol} {timeframe}")
                return None
                
        except Exception as e:
            logging.error(f"âŒ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def calculate_advanced_features(self, df):
        """ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì§€í‘œë“¤
            df['sma_5'] = ta.sma(df['close'], length=5)
            df['sma_10'] = ta.sma(df['close'], length=10)
            df['sma_20'] = ta.sma(df['close'], length=20)
            df['ema_9'] = ta.ema(df['close'], length=9)
            df['ema_21'] = ta.ema(df['close'], length=21)
            
            # MACD
            macd = ta.macd(df['close'], fast=6, slow=13, signal=4)
            df['macd'] = macd['MACD_6_13_4']
            df['macd_signal'] = macd['MACDs_6_13_4']
            df['macd_histogram'] = macd['MACDh_6_13_4']
            
            # RSI
            df['rsi'] = ta.rsi(df['close'], length=9)
            df['rsi_14'] = ta.rsi(df['close'], length=14)
            
            # ë³¼ë¦°ì € ë°´ë“œ
            bb = ta.bbands(df['close'], length=10, std=2)
            df['bb_upper'] = bb['BBU_10_2.0']
            df['bb_lower'] = bb['BBL_10_2.0']
            df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
            
            # ìŠ¤í† ìºìŠ¤í‹±
            stoch = ta.stoch(df['high'], df['low'], df['close'], k=5, d=3)
            df['stoch_k'] = stoch['STOCHk_5_3_3']
            df['stoch_d'] = stoch['STOCHd_5_3_3']
            
            # ATR
            df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=7)
            df['atr_ratio'] = df['atr'] / df['close']
            
            # ADX
            adx = ta.adx(df['high'], df['low'], df['close'], length=7)
            df['adx'] = adx['ADX_7']
            df['di_plus'] = adx['DMP_7']
            df['di_minus'] = adx['DMN_7']
            
            # Williams %R
            df['williams_r'] = ta.willr(df['high'], df['low'], df['close'], length=9)
            
            # Momentum
            df['momentum'] = ta.mom(df['close'], length=10)
            df['momentum_5'] = ta.mom(df['close'], length=5)
            
            # OBV
            df['obv'] = ta.obv(df['close'], df['volume'])
            df['obv_sma'] = ta.sma(df['obv'], length=20)
            
            # CCI
            df['cci'] = ta.cci(df['high'], df['low'], df['close'], length=9)
            
            # Parabolic SAR
            df['psar'] = ta.psar(df['high'], df['low'], df['close'])
            
            # ê°€ê²© ë³€í™”ìœ¨
            df['price_change'] = df['close'].pct_change()
            df['price_change_5'] = df['close'].pct_change(5)
            df['price_change_10'] = df['close'].pct_change(10)
            
            # ë³¼ë¥¨ ì§€í‘œ
            df['volume_sma'] = ta.sma(df['volume'], length=20)
            df['volume_ratio'] = df['volume'] / df['volume_sma']
            
            # ë³€ë™ì„± ì§€í‘œ
            df['volatility'] = df['close'].rolling(20).std()
            df['volatility_ratio'] = df['volatility'] / df['close']
            
            # ì¶”ì„¸ ì§€í‘œ
            df['trend_strength'] = abs(df['ema_9'] - df['ema_21']) / df['close']
            df['trend_direction'] = np.where(df['ema_9'] > df['ema_21'], 1, -1)
            
            # í¬ë¡œìŠ¤ì˜¤ë²„ ì§€í‘œ
            df['ema_cross'] = np.where(df['ema_9'] > df['ema_21'], 1, 0)
            df['ema_cross_change'] = df['ema_cross'].diff()
            
            df['macd_cross'] = np.where(df['macd'] > df['macd_signal'], 1, 0)
            df['macd_cross_change'] = df['macd_cross'].diff()
            
            # ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±
            df['hour'] = df['datetime'].dt.hour
            df['day_of_week'] = df['datetime'].dt.dayofweek
            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
            
            return df
            
        except Exception as e:
            logging.error(f"âŒ ê³ ê¸‰ ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return df
    
    def create_target_variable(self, df, lookforward=5):
        """ëª©í‘œ ë³€ìˆ˜ ìƒì„±"""
        try:
            # ë¯¸ë˜ ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°
            df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1
            
            # ëª©í‘œ ë³€ìˆ˜ ìƒì„±
            df['target'] = np.where(df['future_return'] > 0.01, 1,  # 1% ì´ìƒ ìƒìŠ¹ ì‹œ LONG
                          np.where(df['future_return'] < -0.01, -1, 0))  # 1% ì´ìƒ í•˜ë½ ì‹œ SHORT
            
            # ì‹ í˜¸ ê°•ë„ ê³„ì‚°
            df['signal_strength'] = abs(df['future_return']) * 100
            
            return df
            
        except Exception as e:
            logging.error(f"âŒ ëª©í‘œ ë³€ìˆ˜ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return df
    
    def prepare_features(self, df):
        """íŠ¹ì„± ì¤€ë¹„"""
        try:
            feature_columns = [
                'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',
                'macd', 'macd_signal', 'macd_histogram',
                'rsi', 'rsi_14',
                'bb_upper', 'bb_lower', 'bb_width', 'bb_position',
                'stoch_k', 'stoch_d',
                'atr', 'atr_ratio',
                'adx', 'di_plus', 'di_minus',
                'williams_r', 'momentum', 'momentum_5',
                'obv', 'obv_sma', 'cci', 'psar',
                'price_change', 'price_change_5', 'price_change_10',
                'volume_ratio', 'volatility_ratio',
                'trend_strength', 'trend_direction',
                'ema_cross', 'ema_cross_change',
                'macd_cross', 'macd_cross_change',
                'hour', 'day_of_week', 'is_weekend'
            ]
            
            # NaN ê°’ ì²˜ë¦¬
            df = df.dropna()
            
            # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
            X = df[feature_columns]
            y = df['target']
            
            return X, y, feature_columns
            
        except Exception as e:
            logging.error(f"âŒ íŠ¹ì„± ì¤€ë¹„ ì˜¤ë¥˜: {str(e)}")
            return None, None, None
    
    def train_model_with_hyperparameter_tuning(self, symbol, timeframe, model_type):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ í•¨ê»˜ ëª¨ë¸ í›ˆë ¨"""
        try:
            logging.info(f"ğŸ”„ {symbol} {timeframe} {model_type} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
            
            # ë°ì´í„° ìˆ˜ì§‘
            df = self.get_historical_data(symbol, timeframe, limit=self.optimization_config['data_limit'])
            if df is None or len(df) < 500:
                return False
            
            # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
            df = self.calculate_advanced_features(df)
            df = self.create_target_variable(df)
            
            # íŠ¹ì„± ì¤€ë¹„
            X, y, feature_columns = self.prepare_features(df)
            if X is None:
                return False
            
            self.feature_columns = feature_columns
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
            
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ë¼ë²¨ ì¸ì½”ë”©
            label_encoder = LabelEncoder()
            y_train_encoded = label_encoder.fit_transform(y_train)
            y_test_encoded = label_encoder.transform(y_test)
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
            if model_type == 'random_forest':
                param_grid = {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [10, 20, None],
                    'min_samples_split': [2, 5, 10],
                    'min_samples_leaf': [1, 2, 4]
                }
                base_model = RandomForestClassifier(random_state=42)
            elif model_type == 'xgboost':
                param_grid = {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [3, 6, 9],
                    'learning_rate': [0.01, 0.1, 0.2],
                    'subsample': [0.8, 0.9, 1.0]
                }
                base_model = xgb.XGBClassifier(random_state=42)
            elif model_type == 'lightgbm':
                param_grid = {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [3, 6, 9],
                    'learning_rate': [0.01, 0.1, 0.2],
                    'num_leaves': [31, 62, 127]
                }
                base_model = lgb.LGBMClassifier(random_state=42)
            else:
                return False
            
            # ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¾ê¸°
            grid_search = GridSearchCV(
                base_model,
                param_grid,
                cv=5,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )
            
            grid_search.fit(X_train_scaled, y_train_encoded)
            
            # ìµœì  ëª¨ë¸
            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_
            best_score = grid_search.best_score_
            
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ í‰ê°€
            y_pred = best_model.predict(X_test_scaled)
            test_accuracy = accuracy_score(y_test_encoded, y_pred)
            
            # êµì°¨ ê²€ì¦
            cv_scores = cross_val_score(best_model, X_train_scaled, y_train_encoded, cv=5)
            
            logging.info(f"âœ… {model_type} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ!")
            logging.info(f"ğŸ“Š ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
            logging.info(f"ğŸ“Š CV í‰ê·  ì •í™•ë„: {best_score:.4f}")
            logging.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
            logging.info(f"ğŸ“Š CV í‘œì¤€í¸ì°¨: {cv_scores.std():.4f}")
            
            # ëª¨ë¸ ì €ì¥
            key = f"{symbol}_{timeframe}_{model_type}"
            self.models[key] = best_model
            self.scalers[key] = scaler
            self.label_encoders[key] = label_encoder
            
            # ëª¨ë¸ íŒŒì¼ ì €ì¥
            model_file = self.model_path / f"{key}_model.pkl"
            scaler_file = self.model_path / f"{key}_scaler.pkl"
            encoder_file = self.model_path / f"{key}_encoder.pkl"
            
            joblib.dump(best_model, model_file)
            joblib.dump(scaler, scaler_file)
            joblib.dump(label_encoder, encoder_file)
            
            # ì„±ëŠ¥ ê¸°ë¡
            performance_record = {
                'timestamp': datetime.now().isoformat(),
                'symbol': symbol,
                'timeframe': timeframe,
                'model_type': model_type,
                'best_params': best_params,
                'cv_accuracy': best_score,
                'test_accuracy': test_accuracy,
                'cv_std': cv_scores.std(),
                'best_score': best_score
            }
            
            self.save_performance_record(performance_record)
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def run_comprehensive_backtest(self, symbol, timeframe, params=None):
        """ì¢…í•© ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
        try:
            if params is None:
                params = self.optimized_params
            
            # ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ (ë” ê¸´ ê¸°ê°„)
            days_back = self.optimization_config['backtest_days']
            limit = days_back * 24 * 60  # 1ë¶„ë´‰ ê¸°ì¤€
            
            df = self.get_historical_data(symbol, timeframe, limit=limit)
            if df is None:
                return None
            
            # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
            df = self.calculate_advanced_features(df)
            
            # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼
            trades = []
            position = None
            entry_price = 0
            entry_time = None
            account_balance = 10000  # ì´ˆê¸° ìë³¸
            current_balance = account_balance
            
            for i in range(100, len(df)):
                current_data = df.iloc[:i+1]
                
                # ì‹ í˜¸ ì˜ˆì¸¡ (ì—¬ëŸ¬ ëª¨ë¸ì˜ ì•™ìƒë¸”)
                ensemble_signal = self.get_ensemble_signal(symbol, timeframe, current_data)
                
                if ensemble_signal is None:
                    continue
                
                current_price = df.iloc[i]['close']
                current_time = df.iloc[i]['datetime']
                
                # í¬ì§€ì…˜ ì§„ì… ì¡°ê±´
                if position is None and ensemble_signal['confidence'] >= params['min_confidence']:
                    if ensemble_signal['action'] in [1, -1]:  # LONG ë˜ëŠ” SHORT
                        position = ensemble_signal['action']
                        entry_price = current_price
                        entry_time = current_time
                        
                        # í¬ì§€ì…˜ í¬ê¸° ê³„ì‚°
                        position_size = current_balance * params['position_size']
                        quantity = position_size / current_price
                        
                        trades.append({
                            'entry_time': entry_time,
                            'entry_price': entry_price,
                            'position': 'LONG' if position == 1 else 'SHORT',
                            'confidence': ensemble_signal['confidence'],
                            'quantity': quantity,
                            'position_size': position_size
                        })
                
                # í¬ì§€ì…˜ ì²­ì‚° ì¡°ê±´
                elif position is not None:
                    # ATR ê³„ì‚°
                    atr = df.iloc[i]['atr']
                    
                    # ì†ì ˆ/ìµì ˆ ê³„ì‚°
                    if position == 1:  # LONG
                        stop_loss = entry_price - (atr * params['stop_loss_atr'])
                        take_profit = entry_price + (atr * params['take_profit_atr'])
                        
                        if current_price <= stop_loss or current_price >= take_profit:
                            # ì²­ì‚°
                            exit_price = current_price
                            pnl = (exit_price - entry_price) / entry_price
                            
                            # ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°
                            trade_pnl = trades[-1]['position_size'] * pnl
                            current_balance += trade_pnl
                            
                            trades[-1].update({
                                'exit_time': current_time,
                                'exit_price': exit_price,
                                'pnl': pnl,
                                'trade_pnl': trade_pnl,
                                'current_balance': current_balance,
                                'exit_reason': 'stop_loss' if current_price <= stop_loss else 'take_profit'
                            })
                            
                            position = None
                    
                    elif position == -1:  # SHORT
                        stop_loss = entry_price + (atr * params['stop_loss_atr'])
                        take_profit = entry_price - (atr * params['take_profit_atr'])
                        
                        if current_price >= stop_loss or current_price <= take_profit:
                            # ì²­ì‚°
                            exit_price = current_price
                            pnl = (entry_price - exit_price) / entry_price
                            
                            # ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°
                            trade_pnl = trades[-1]['position_size'] * pnl
                            current_balance += trade_pnl
                            
                            trades[-1].update({
                                'exit_time': current_time,
                                'exit_price': exit_price,
                                'pnl': pnl,
                                'trade_pnl': trade_pnl,
                                'current_balance': current_balance,
                                'exit_reason': 'stop_loss' if current_price >= stop_loss else 'take_profit'
                            })
                            
                            position = None
                
                # ìµœëŒ€ ë³´ìœ  ì‹œê°„ ì²´í¬
                if position is not None and entry_time:
                    holding_time = (current_time - entry_time).total_seconds() / 3600
                    if holding_time > params.get('max_holding_time', 24):
                        # ê°•ì œ ì²­ì‚°
                        exit_price = current_price
                        if position == 1:
                            pnl = (exit_price - entry_price) / entry_price
                        else:
                            pnl = (entry_price - exit_price) / entry_price
                        
                        trade_pnl = trades[-1]['position_size'] * pnl
                        current_balance += trade_pnl
                        
                        trades[-1].update({
                            'exit_time': current_time,
                            'exit_price': exit_price,
                            'pnl': pnl,
                            'trade_pnl': trade_pnl,
                            'current_balance': current_balance,
                            'exit_reason': 'timeout'
                        })
                        
                        position = None
            
            # ê²°ê³¼ ê³„ì‚°
            if not trades:
                return None
            
            completed_trades = [t for t in trades if 'exit_price' in t]
            
            if not completed_trades:
                return None
            
            # ê¸°ë³¸ í†µê³„
            total_return = (current_balance - account_balance) / account_balance
            win_trades = [t for t in completed_trades if t['pnl'] > 0]
            win_rate = len(win_trades) / len(completed_trades)
            
            returns = [t['pnl'] for t in completed_trades]
            sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
            
            # ìµœëŒ€ ë‚™í­ ê³„ì‚°
            balance_history = [t['current_balance'] for t in completed_trades]
            peak = account_balance
            max_drawdown = 0
            
            for balance in balance_history:
                if balance > peak:
                    peak = balance
                drawdown = (balance - peak) / peak
                if drawdown < max_drawdown:
                    max_drawdown = drawdown
            
            # ì¶”ê°€ ì§€í‘œ
            avg_win = np.mean([t['pnl'] for t in win_trades]) if win_trades else 0
            avg_loss = np.mean([t['pnl'] for t in completed_trades if t['pnl'] < 0]) if any(t['pnl'] < 0 for t in completed_trades) else 0
            profit_factor = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')
            
            results = {
                'total_trades': len(completed_trades),
                'win_rate': win_rate,
                'total_return': total_return,
                'sharpe_ratio': sharpe_ratio,
                'max_drawdown': max_drawdown,
                'avg_win': avg_win,
                'avg_loss': avg_loss,
                'profit_factor': profit_factor,
                'final_balance': current_balance,
                'initial_balance': account_balance,
                'trades': completed_trades,
                'params': params
            }
            
            return results
            
        except Exception as e:
            logging.error(f"âŒ ì¢…í•© ë°±í…ŒìŠ¤íŒ… ì˜¤ë¥˜: {str(e)}")
            return None
    
    def get_ensemble_signal(self, symbol, timeframe, current_data):
        """ì•™ìƒë¸” ì‹ í˜¸ ìƒì„±"""
        try:
            signals = []
            weights = []
            
            # ê° ëª¨ë¸ì—ì„œ ì‹ í˜¸ ê°€ì ¸ì˜¤ê¸°
            for model_type in self.optimization_config['models']:
                key = f"{symbol}_{timeframe}_{model_type}"
                
                if key in self.models:
                    signal = self.predict_signal(symbol, timeframe, current_data, model_type)
                    if signal:
                        signals.append(signal)
                        # ëª¨ë¸ ì„±ëŠ¥ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                        weight = self.get_model_weight(key)
                        weights.append(weight)
            
            if not signals:
                return None
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸” ì‹ í˜¸ ìƒì„±
            ensemble_action = 0
            ensemble_confidence = 0
            total_weight = sum(weights)
            
            for signal, weight in zip(signals, weights):
                ensemble_action += signal['action'] * (weight / total_weight)
                ensemble_confidence += signal['confidence'] * (weight / total_weight)
            
            # ì•™ìƒë¸” ì•¡ì…˜ ê²°ì •
            if ensemble_action > 0.5:
                final_action = 1
            elif ensemble_action < -0.5:
                final_action = -1
            else:
                final_action = 0
            
            return {
                'symbol': symbol.upper(),
                'timeframe': timeframe,
                'action': final_action,
                'confidence': ensemble_confidence,
                'ensemble_action': ensemble_action,
                'datetime': datetime.now()
            }
            
        except Exception as e:
            logging.error(f"âŒ ì•™ìƒë¸” ì‹ í˜¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def predict_signal(self, symbol, timeframe, current_data, model_type):
        """ê°œë³„ ëª¨ë¸ ì‹ í˜¸ ì˜ˆì¸¡"""
        try:
            key = f"{symbol}_{timeframe}_{model_type}"
            
            if key not in self.models:
                return None
            
            model = self.models[key]
            scaler = self.scalers[key]
            label_encoder = self.label_encoders[key]
            
            # íŠ¹ì„± ê³„ì‚°
            features = self.calculate_advanced_features(current_data)
            if features is None or len(features) < 50:
                return None
            
            # ìµœì‹  ë°ì´í„° ì¶”ì¶œ
            latest_features = features[self.feature_columns].iloc[-1:].values
            
            # ìŠ¤ì¼€ì¼ë§
            scaled_features = scaler.transform(latest_features)
            
            # ì˜ˆì¸¡
            prediction = model.predict(scaled_features)[0]
            probabilities = model.predict_proba(scaled_features)[0]
            
            # ì‹ í˜¸ ìƒì„±
            signal = {
                'symbol': symbol.upper(),
                'timeframe': timeframe,
                'prediction': prediction,
                'probabilities': probabilities,
                'confidence': max(probabilities),
                'action': label_encoder.inverse_transform([prediction])[0],
                'datetime': datetime.now()
            }
            
            return signal
            
        except Exception as e:
            logging.error(f"âŒ ì‹ í˜¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def get_model_weight(self, model_key):
        """ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        try:
            # ì„±ëŠ¥ ê¸°ë¡ì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³„ì‚°
            performance_file = self.performance_db / f"{model_key}_performance.json"
            
            if performance_file.exists():
                with open(performance_file, 'r') as f:
                    performance_data = json.load(f)
                
                # ìµœê·¼ ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜
                recent_performance = performance_data.get('recent_accuracy', 0.5)
                return recent_performance
            else:
                return 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
                
        except Exception as e:
            logging.error(f"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 1.0
    
    def continuous_parameter_optimization(self):
        """ì§€ì†ì ì¸ íŒŒë¼ë¯¸í„° ìµœì í™”"""
        try:
            logging.info("ğŸ”„ ì§€ì†ì ì¸ íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")
            
            best_overall_params = self.optimized_params.copy()
            best_overall_sharpe = -999
            
            # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (ë” ì„¸ë°€í•˜ê²Œ)
            param_grid = {
                'signal_threshold': [1.5, 2.0, 2.5, 3.0, 3.5, 4.0],
                'stop_loss_atr': [1.0, 1.5, 2.0, 2.5, 3.0],
                'take_profit_atr': [2.0, 3.0, 4.0, 5.0, 6.0],
                'min_confidence': [0.6, 0.7, 0.8, 0.85, 0.9],
                'position_size': [0.01, 0.02, 0.03, 0.05]
            }
            
            total_combinations = len(param_grid['signal_threshold']) * len(param_grid['stop_loss_atr']) * len(param_grid['take_profit_atr']) * len(param_grid['min_confidence']) * len(param_grid['position_size'])
            
            logging.info(f"ğŸ“Š ì´ {total_combinations}ê°œ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            combination_count = 0
            
            for threshold in param_grid['signal_threshold']:
                for stop_loss in param_grid['stop_loss_atr']:
                    for take_profit in param_grid['take_profit_atr']:
                        for confidence in param_grid['min_confidence']:
                            for position_size in param_grid['position_size']:
                                
                                combination_count += 1
                                logging.info(f"ğŸ”„ ì§„í–‰ë¥ : {combination_count}/{total_combinations}")
                                
                                params = {
                                    'signal_threshold': threshold,
                                    'stop_loss_atr': stop_loss,
                                    'take_profit_atr': take_profit,
                                    'min_confidence': confidence,
                                    'position_size': position_size
                                }
                                
                                # ëª¨ë“  ì‹¬ë³¼ê³¼ íƒ€ì„í”„ë ˆì„ì— ëŒ€í•´ ë°±í…ŒìŠ¤íŒ…
                                total_sharpe = 0
                                valid_results = 0
                                
                                for symbol in self.optimization_config['symbols']:
                                    for timeframe in self.optimization_config['timeframes']:
                                        results = self.run_comprehensive_backtest(symbol, timeframe, params)
                                        
                                        if results and results['sharpe_ratio'] > 0:
                                            total_sharpe += results['sharpe_ratio']
                                            valid_results += 1
                                
                                # í‰ê·  Sharpe Ratio ê³„ì‚°
                                if valid_results > 0:
                                    avg_sharpe = total_sharpe / valid_results
                                    
                                    if avg_sharpe > best_overall_sharpe:
                                        best_overall_sharpe = avg_sharpe
                                        best_overall_params = params.copy()
                                        
                                        logging.info(f"ğŸ”¥ ìƒˆë¡œìš´ ìµœê³  íŒŒë¼ë¯¸í„° ë°œê²¬!")
                                        logging.info(f"ğŸ“Š í‰ê·  Sharpe: {avg_sharpe:.4f}")
                                        logging.info(f"âš™ï¸ íŒŒë¼ë¯¸í„°: {params}")
            
            self.optimized_params = best_overall_params
            
            # ìµœì í™” ê¸°ë¡ ì €ì¥
            optimization_record = {
                'timestamp': datetime.now().isoformat(),
                'best_params': best_overall_params,
                'best_sharpe': best_overall_sharpe,
                'total_combinations_tested': total_combinations
            }
            
            self.save_optimization_record(optimization_record)
            
            logging.info(f"âœ… ì§€ì†ì ì¸ íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!")
            logging.info(f"ğŸ“Š ìµœê³  Sharpe Ratio: {best_overall_sharpe:.4f}")
            logging.info(f"âš™ï¸ ìµœì  íŒŒë¼ë¯¸í„°: {best_overall_params}")
            
            return best_overall_params
            
        except Exception as e:
            logging.error(f"âŒ ì§€ì†ì ì¸ íŒŒë¼ë¯¸í„° ìµœì í™” ì˜¤ë¥˜: {str(e)}")
            return self.optimized_params
    
    def save_performance_record(self, record):
        """ì„±ëŠ¥ ê¸°ë¡ ì €ì¥"""
        try:
            key = f"{record['symbol']}_{record['timeframe']}_{record['model_type']}"
            performance_file = self.performance_db / f"{key}_performance.json"
            
            # ê¸°ì¡´ ê¸°ë¡ ë¡œë“œ
            if performance_file.exists():
                with open(performance_file, 'r') as f:
                    existing_data = json.load(f)
            else:
                existing_data = {'history': []}
            
            # ìƒˆ ê¸°ë¡ ì¶”ê°€
            existing_data['history'].append(record)
            
            # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            if len(existing_data['history']) > 10:
                existing_data['history'] = existing_data['history'][-10:]
            
            # ìµœê·¼ ì„±ëŠ¥ ê³„ì‚°
            recent_performances = [r['test_accuracy'] for r in existing_data['history']]
            existing_data['recent_accuracy'] = np.mean(recent_performances)
            
            # íŒŒì¼ ì €ì¥
            with open(performance_file, 'w') as f:
                json.dump(existing_data, f, indent=2)
                
        except Exception as e:
            logging.error(f"âŒ ì„±ëŠ¥ ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
    
    def save_optimization_record(self, record):
        """ìµœì í™” ê¸°ë¡ ì €ì¥"""
        try:
            optimization_file = self.performance_db / 'optimization_history.json'
            
            # ê¸°ì¡´ ê¸°ë¡ ë¡œë“œ
            if optimization_file.exists():
                with open(optimization_file, 'r') as f:
                    existing_data = json.load(f)
            else:
                existing_data = {'history': []}
            
            # ìƒˆ ê¸°ë¡ ì¶”ê°€
            existing_data['history'].append(record)
            
            # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
            if len(existing_data['history']) > 50:
                existing_data['history'] = existing_data['history'][-50:]
            
            # íŒŒì¼ ì €ì¥
            with open(optimization_file, 'w') as f:
                json.dump(existing_data, f, indent=2)
                
        except Exception as e:
            logging.error(f"âŒ ìµœì í™” ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
    
    def check_performance_degradation(self):
        """ì„±ëŠ¥ ì €í•˜ í™•ì¸"""
        try:
            logging.info("ğŸ” ì„±ëŠ¥ ì €í•˜ í™•ì¸ ì¤‘...")
            
            for symbol in self.optimization_config['symbols']:
                for timeframe in self.optimization_config['timeframes']:
                    for model_type in self.optimization_config['models']:
                        key = f"{symbol}_{timeframe}_{model_type}"
                        performance_file = self.performance_db / f"{key}_performance.json"
                        
                        if performance_file.exists():
                            with open(performance_file, 'r') as f:
                                data = json.load(f)
                            
                            if 'history' in data and len(data['history']) >= 2:
                                recent_accuracy = data['history'][-1]['test_accuracy']
                                previous_accuracy = data['history'][-2]['test_accuracy']
                                
                                # ì„±ëŠ¥ ì €í•˜ í™•ì¸ (5% ì´ìƒ í•˜ë½)
                                if recent_accuracy < previous_accuracy * 0.95:
                                    logging.warning(f"âš ï¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€: {key}")
                                    logging.warning(f"ğŸ“Š ì´ì „: {previous_accuracy:.4f} â†’ í˜„ì¬: {recent_accuracy:.4f}")
                                    
                                    # ì¬í›ˆë ¨ í•„ìš” í‘œì‹œ
                                    return True
            
            return False
            
        except Exception as e:
            logging.error(f"âŒ ì„±ëŠ¥ ì €í•˜ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def schedule_optimization_tasks(self):
        """ìµœì í™” ì‘ì—… ìŠ¤ì¼€ì¤„ë§"""
        try:
            # 24ì‹œê°„ë§ˆë‹¤ ëª¨ë¸ ì¬í›ˆë ¨
            schedule.every(self.optimization_config['retrain_interval_hours']).hours.do(self.retrain_all_models)
            
            # 6ì‹œê°„ë§ˆë‹¤ íŒŒë¼ë¯¸í„° ìµœì í™”
            schedule.every(self.optimization_config['optimization_interval_hours']).hours.do(self.continuous_parameter_optimization)
            
            # 1ì‹œê°„ë§ˆë‹¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            schedule.every().hour.do(self.check_performance_degradation)
            
            logging.info("ğŸ“… ìµœì í™” ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ì™„ë£Œ!")
            
        except Exception as e:
            logging.error(f"âŒ ìŠ¤ì¼€ì¤„ë§ ì˜¤ë¥˜: {str(e)}")
    
    def retrain_all_models(self):
        """ëª¨ë“  ëª¨ë¸ ì¬í›ˆë ¨"""
        try:
            logging.info("ğŸ”„ ëª¨ë“  ëª¨ë¸ ì¬í›ˆë ¨ ì‹œì‘...")
            
            success_count = 0
            total_count = len(self.optimization_config['symbols']) * len(self.optimization_config['timeframes']) * len(self.optimization_config['models'])
            
            for symbol in self.optimization_config['symbols']:
                for timeframe in self.optimization_config['timeframes']:
                    for model_type in self.optimization_config['models']:
                        try:
                            if self.train_model_with_hyperparameter_tuning(symbol, timeframe, model_type):
                                success_count += 1
                                logging.info(f"âœ… {symbol} {timeframe} {model_type} ì¬í›ˆë ¨ ì„±ê³µ!")
                            else:
                                logging.error(f"âŒ {symbol} {timeframe} {model_type} ì¬í›ˆë ¨ ì‹¤íŒ¨!")
                        except Exception as e:
                            logging.error(f"âŒ {symbol} {timeframe} {model_type} ì¬í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
            
            logging.info(f"ğŸ‰ ëª¨ë¸ ì¬í›ˆë ¨ ì™„ë£Œ! ì„±ê³µ: {success_count}/{total_count}")
            
        except Exception as e:
            logging.error(f"âŒ ëª¨ë¸ ì¬í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
    
    def run_continuous_optimization(self):
        """ì§€ì†ì ì¸ ìµœì í™” ì‹¤í–‰"""
        try:
            logging.info("ğŸš€ ì§€ì†ì ì¸ ìµœì í™” ì‹œìŠ¤í…œ ì‹œì‘...")
            
            # ì´ˆê¸° ëª¨ë¸ í›ˆë ¨
            self.retrain_all_models()
            
            # ì´ˆê¸° íŒŒë¼ë¯¸í„° ìµœì í™”
            self.continuous_parameter_optimization()
            
            # ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
            self.schedule_optimization_tasks()
            
            # ì§€ì†ì ì¸ ì‹¤í–‰
            while self.is_running:
                try:
                    schedule.run_pending()
                    time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
                    
                except KeyboardInterrupt:
                    logging.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                except Exception as e:
                    logging.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                    time.sleep(300)  # 5ë¶„ ëŒ€ê¸° í›„ ì¬ì‹œë„
            
        except Exception as e:
            logging.error(f"âŒ ì§€ì†ì ì¸ ìµœì í™” ì˜¤ë¥˜: {str(e)}")
    
    def start(self):
        """ì§€ì†ì ì¸ ìµœì í™” ì‹œìŠ¤í…œ ì‹œì‘"""
        self.is_running = True
        logging.info("ğŸš€ ì§€ì†ì ì¸ íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ ì‹œì‘...")
        
        try:
            self.run_continuous_optimization()
        except KeyboardInterrupt:
            logging.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logging.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        finally:
            self.stop()
    
    def stop(self):
        """ì§€ì†ì ì¸ ìµœì í™” ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.is_running = False
        logging.info("ì§€ì†ì ì¸ íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì§€ì†ì ì¸ íŒŒì¸íŠœë‹ ë° ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        optimization_system = ContinuousOptimizationSystem()
        optimization_system.start()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
