{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ ADAUSDT 1ë¶„ë´‰ LightGBM ëª¨ë¸ í›ˆë ¨ (ìµœì í™” ë²„ì „)\n",
    "\n",
    "## ğŸ“Š ë°ì´í„°: ë°°ì¹˜ ìˆ˜ì§‘ìœ¼ë¡œ ìµœëŒ€ ë°ì´í„° í™•ë³´\n",
    "## ğŸ¤– ëª¨ë¸: LightGBM\n",
    "## ğŸ¯ ëª©í‘œ: 5ë¶„ í›„ ìˆ˜ìµë¥  ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "%pip install pandas==2.0.3 numpy==1.24.3 scikit-learn==1.3.0 xgboost==1.7.6 lightgbm==4.0.0 tensorflow==2.13.0 pandas-ta==0.3.14b0 supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from supabase import create_client\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ')\n",
    "print(f'pandas: {pd.__version__}')\n",
    "print(f'numpy: {np.__version__}')\n",
    "print(f'lightgbm: {lgb.__version__}')\n",
    "print(f'xgboost: {xgb.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”‘ Supabase ì—°ê²° ì„¤ì •\n",
    "SUPABASE_URL = 'https://yyvnfhezxkufzqdbqdni.supabase.co'\n",
    "SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inl5dm5maGV6eGt1ZnpxZGJxZG5pIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTY0MzMzODgsImV4cCI6MjA3MjAwOTM4OH0.4J9nwFo27szlzY8M1aMxs1UlDlGYmucGnD5u5P-UFBY'\n",
    "\n",
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "print('âœ… Supabase ì—°ê²° ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ (ìµœì í™” ë²„ì „)\n",
    "def collect_data_in_batches():\n",
    "    \"\"\"ë°°ì¹˜ë¡œ ë°ì´í„° ìˆ˜ì§‘\"\"\"\n",
    "    \n",
    "    print('ğŸ“Š ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...')\n",
    "    \n",
    "    # ë°°ì¹˜ í¬ê¸° (Supabase ì œí•œ ê³ ë ¤)\n",
    "    batch_size = 1000\n",
    "    all_data = []\n",
    "    \n",
    "    # ìµœì‹  ë°ì´í„°ë¶€í„° ë°°ì¹˜ë¡œ ìˆ˜ì§‘\n",
    "    offset = 0\n",
    "    total_collected = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            print(f'ë°°ì¹˜ {offset//batch_size + 1} ìˆ˜ì§‘ ì¤‘... (offset: {offset})')\n",
    "            \n",
    "            response = supabase.table('crypto_ohlcv').select('*').eq('symbol', 'ADAUSDT').eq('timeframe', '1m').order('timestamp', desc=True).range(offset, offset + batch_size - 1).execute()\n",
    "            \n",
    "            if not response.data:\n",
    "                print('ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')\n",
    "                break\n",
    "                \n",
    "            batch_data = response.data\n",
    "            all_data.extend(batch_data)\n",
    "            total_collected += len(batch_data)\n",
    "            \n",
    "            print(f'âœ… ë°°ì¹˜ {offset//batch_size + 1} ì™„ë£Œ: {len(batch_data)}ê°œ (ì´ {total_collected:,}ê°œ)')\n",
    "            \n",
    "            # ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©´ ì¤‘ë‹¨\n",
    "            if total_collected >= 50000:  # 5ë§Œê°œë¡œ ì œí•œ\n",
    "                print(f'ëª©í‘œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {total_collected:,}ê°œ')\n",
    "                break\n",
    "                \n",
    "            offset += batch_size\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'âŒ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}')\n",
    "            break\n",
    "    \n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df = df.sort_values('datetime')\n",
    "        \n",
    "        print(f'\nâœ… ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ:')\n",
    "        print(f'ğŸ“Š ì´ ë°ì´í„°: {len(df):,}ê°œ')\n",
    "        print(f'ğŸ“… ê¸°ê°„: {df["datetime"].min()} ~ {df["datetime"].max()}')\n",
    "        print(f'ğŸ“ˆ ë°ì´í„° í¬ê¸°: {df.shape}')\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print('âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨')\n",
    "        return None\n",
    "\n",
    "# ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰\n",
    "df = collect_data_in_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§® ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (ìµœì í™” ë²„ì „)\n",
    "def calculate_advanced_features(df):\n",
    "    print('ğŸ§® ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹œì‘...')\n",
    "    \n",
    "    # ê¸°ë³¸ ì§€í‘œë“¤\n",
    "    df['sma_5'] = ta.sma(df['close'], length=5)\n",
    "    df['sma_10'] = ta.sma(df['close'], length=10)\n",
    "    df['sma_20'] = ta.sma(df['close'], length=20)\n",
    "    df['ema_9'] = ta.ema(df['close'], length=9)\n",
    "    df['ema_21'] = ta.ema(df['close'], length=21)\n",
    "    \n",
    "    # RSI\n",
    "    df['rsi'] = ta.rsi(df['close'], length=14)\n",
    "    \n",
    "    # MACD\n",
    "    macd = ta.macd(df['close'], fast=6, slow=13, signal=4)\n",
    "    df['macd'] = macd['MACD_6_13_4']\n",
    "    df['macd_signal'] = macd['MACDs_6_13_4']\n",
    "    df['macd_histogram'] = macd['MACDh_6_13_4']\n",
    "    \n",
    "    # ë³¼ë¦°ì € ë°´ë“œ\n",
    "    bb = ta.bbands(df['close'], length=10, std=2)\n",
    "    df['bb_upper'] = bb['BBU_10_2.0']\n",
    "    df['bb_lower'] = bb['BBL_10_2.0']\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']\n",
    "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
    "    \n",
    "    # ê°€ê²© ë³€í™”ìœ¨\n",
    "    df['price_change'] = df['close'].pct_change()\n",
    "    df['price_change_5'] = df['close'].pct_change(5)\n",
    "    df['price_change_10'] = df['close'].pct_change(10)\n",
    "    \n",
    "    # ë³¼ë¥¨ ì§€í‘œ\n",
    "    df['volume_sma'] = ta.sma(df['volume'], length=20)\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
    "    \n",
    "    # ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    print('âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ')\n",
    "    return df\n",
    "\n",
    "# ì§€í‘œ ê³„ì‚°\n",
    "df = calculate_advanced_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ëª©í‘œ ë³€ìˆ˜ ìƒì„± (ê°œì„ ëœ ë²„ì „)\n",
    "def create_target_variable(df, lookforward=5, threshold=0.005):  # 0.5% ì„ê³„ê°’\n",
    "    # ë¯¸ë˜ ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°\n",
    "    df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1\n",
    "    \n",
    "    # ëª©í‘œ ë³€ìˆ˜ ìƒì„± (ë” ê· í˜•ì¡íŒ ë¶„ë¥˜)\n",
    "    df['target'] = np.where(df['future_return'] > threshold, 1,    # 0.5% ì´ìƒ ìƒìŠ¹ ì‹œ LONG\n",
    "                      np.where(df['future_return'] < -threshold, -1, 0))  # 0.5% ì´ìƒ í•˜ë½ ì‹œ SHORT\n",
    "    \n",
    "    # ì‹ í˜¸ ê°•ë„ ê³„ì‚°\n",
    "    df['signal_strength'] = abs(df['future_return']) * 100\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
    "df = create_target_variable(df)\n",
    "print('âœ… ëª©í‘œ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ')\n",
    "print(f'ğŸ“Š íƒ€ê²Ÿ ë¶„í¬:\n{df["target"].value_counts()}')\n",
    "print(f'ğŸ“ˆ ì‹ í˜¸ ê°•ë„ í‰ê· : {df["signal_strength"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ íŠ¹ì„± ì¤€ë¹„\n",
    "feature_columns = [\n",
    "    'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',\n",
    "    'macd', 'macd_signal', 'macd_histogram',\n",
    "    'rsi',\n",
    "    'bb_upper', 'bb_lower', 'bb_width', 'bb_position',\n",
    "    'price_change', 'price_change_5', 'price_change_10',\n",
    "    'volume_sma', 'volume_ratio',\n",
    "    'hour', 'day_of_week', 'is_weekend'\n",
    "]\n",
    "\n",
    "# NaN ê°’ ì²˜ë¦¬\n",
    "df = df.dropna()\n",
    "\n",
    "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "X = df[feature_columns]\n",
    "y = df['target']\n",
    "\n",
    "print(f'âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ')\n",
    "print(f'ğŸ“Š íŠ¹ì„± ê°œìˆ˜: {len(feature_columns)}')\n",
    "print(f'ğŸ“ˆ ë°ì´í„° í¬ê¸°: {X.shape}')\n",
    "print(f'ğŸ¯ íƒ€ê²Ÿ ë¶„í¬: {y.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ LightGBM ëª¨ë¸ í›ˆë ¨\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# LightGBM ëª¨ë¸ ì„¤ì •\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print('ğŸš€ LightGBM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...')\n",
    "print(f'ğŸ“Š í›ˆë ¨ ë°ì´í„°: {X_train.shape}')\n",
    "print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}')\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ')\n",
    "print(f'ğŸ“Š ì •í™•ë„: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# êµì°¨ ê²€ì¦\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print('ğŸ“Š êµì°¨ ê²€ì¦ ê²°ê³¼:')\n",
    "print(f'í‰ê·  ì •í™•ë„: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})')\n",
    "print(f'ê°œë³„ ì •í™•ë„: {cv_scores}')\n",
    "\n",
    "# ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
    "print('\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# íŠ¹ì„± ì¤‘ìš”ë„\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('\nğŸ† ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:')\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ ëª¨ë¸ ì €ì¥\n",
    "import os\n",
    "\n",
    "# models ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "model_filename = f'adausdt_1m_lightgbm_model.pkl'\n",
    "with open(f'models/{model_filename}', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "results = {\n",
    "    'symbol': 'adausdt',\n",
    "    'timeframe': '1m',\n",
    "    'model_type': 'lightgbm',\n",
    "    'accuracy': accuracy,\n",
    "    'cv_mean': cv_scores.mean(),\n",
    "    'cv_std': cv_scores.std(),\n",
    "    'data_size': len(df),\n",
    "    'feature_count': len(feature_columns),\n",
    "    'target_distribution': y.value_counts().to_dict()\n",
    "}\n",
    "\n",
    "results_filename = f'adausdt_1m_lightgbm_results.json'\n",
    "with open(f'models/{results_filename}', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print('âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ')\n",
    "print(f'ğŸ“ ëª¨ë¸ íŒŒì¼: models/{model_filename}')\n",
    "print(f'ğŸ“ ê²°ê³¼ íŒŒì¼: models/{results_filename}')\n",
    "print(f'\nğŸ‰ ADAUSDT 1m LightGBM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}