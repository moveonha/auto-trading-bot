import os
import json
import requests
import time
import logging
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
from supabase import create_client
import base64
import zipfile
import io

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('colab_training.log'),
        logging.StreamHandler()
    ]
)

class ColabTrainingSystem:
    def __init__(self):
        self.load_env_file()
        self.supabase = self.get_supabase_client()
        
        # Colab API ì„¤ì •
        self.colab_api_url = "https://colab.research.google.com/api"
        self.session = requests.Session()
        
        # í›ˆë ¨ ì„¤ì •
        self.training_config = {
            'symbols': ['btcusdt', 'ethusdt', 'bnbusdt', 'adausdt', 'solusdt'],
            'timeframes': ['1m', '5m', '15m', '1h'],
            'models': ['random_forest', 'xgboost', 'lightgbm', 'lstm'],
            'data_limit': 3000,
            'sequence_length': 60,
            'epochs': 100,
            'batch_size': 32
        }
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_path = Path('colab_models')
        self.model_path.mkdir(exist_ok=True)
        
    def load_env_file(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        config_file = Path('.env')
        if not config_file.exists():
            raise FileNotFoundError(".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with open(config_file, 'r') as f:
            for line in f:
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value
    
    def get_supabase_client(self):
        """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        if not url or not key:
            raise ValueError("Supabase URL ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return create_client(url, key)
    
    def get_training_data(self, symbol, timeframe):
        """í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            logging.info(f"ğŸ“Š {symbol} {timeframe} í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # Supabaseì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            response = self.supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol.upper()).eq('timeframe', timeframe).order('timestamp', desc=True).limit(self.training_config['data_limit']).execute()
            
            if response.data:
                df = pd.DataFrame(response.data)
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df.sort_values('datetime')
                
                logging.info(f"âœ… {symbol} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ")
                return df
            else:
                logging.warning(f"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {symbol} {timeframe}")
                return None
                
        except Exception as e:
            logging.error(f"âŒ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def prepare_colab_notebook(self, symbol, timeframe, model_type):
        """Colab ë…¸íŠ¸ë¶ ìƒì„±"""
        try:
            notebook_content = self.generate_notebook_code(symbol, timeframe, model_type)
            
            # ë…¸íŠ¸ë¶ íŒŒì¼ ìƒì„±
            notebook_file = self.model_path / f"{symbol}_{timeframe}_{model_type}_training.ipynb"
            
            with open(notebook_file, 'w', encoding='utf-8') as f:
                f.write(notebook_content)
            
            logging.info(f"ğŸ“ Colab ë…¸íŠ¸ë¶ ìƒì„± ì™„ë£Œ: {notebook_file}")
            return notebook_file
            
        except Exception as e:
            logging.error(f"âŒ ë…¸íŠ¸ë¶ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def generate_notebook_code(self, symbol, timeframe, model_type):
        """ë…¸íŠ¸ë¶ ì½”ë“œ ìƒì„±"""
        notebook_template = {
            "cells": [
                {
                    "cell_type": "markdown",
                    "metadata": {},
                    "source": [
                        f"# ğŸ¤– {symbol.upper()} {timeframe} {model_type.upper()} ëª¨ë¸ í›ˆë ¨\n",
                        f"## ì•”í˜¸í™”í íŠ¸ë ˆì´ë”© ì‹ í˜¸ ìµœì í™”\n",
                        f"- ì‹¬ë³¼: {symbol.upper()}\n",
                        f"- íƒ€ì„í”„ë ˆì„: {timeframe}\n",
                        f"- ëª¨ë¸: {model_type.upper()}\n",
                        f"- ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
                        "!pip install pandas numpy scikit-learn xgboost lightgbm tensorflow pandas-ta supabase"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
                        "import pandas as pd\n",
                        "import numpy as np\n",
                        "import pandas_ta as ta\n",
                        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                        "from sklearn.model_selection import train_test_split, cross_val_score\n",
                        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                        "from sklearn.metrics import classification_report, accuracy_score\n",
                        "import xgboost as xgb\n",
                        "import lightgbm as lgb\n",
                        "import tensorflow as tf\n",
                        "from tensorflow.keras.models import Sequential\n",
                        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
                        "from tensorflow.keras.optimizers import Adam\n",
                        "from tensorflow.keras.callbacks import EarlyStopping\n",
                        "from supabase import create_client\n",
                        "import joblib\n",
                        "import warnings\n",
                        "warnings.filterwarnings('ignore')\n",
                        "\n",
                        "print('âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ”‘ Supabase ì—°ê²° ì„¤ì •\n",
                        "SUPABASE_URL = 'YOUR_SUPABASE_URL'\n",
                        "SUPABASE_KEY = 'YOUR_SUPABASE_KEY'\n",
                        "\n",
                        "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
                        "print('âœ… Supabase ì—°ê²° ì™„ë£Œ')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ“Š ë°ì´í„° ìˆ˜ì§‘\n",
                        "symbol = '{symbol}'\n",
                        "timeframe = '{timeframe}'\n",
                        "data_limit = {self.training_config['data_limit']}\n",
                        "\n",
                        "response = supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol.upper()).eq('timeframe', timeframe).order('timestamp', desc=True).limit(data_limit).execute()\n",
                        "\n",
                        "if response.data:\n",
                        "    df = pd.DataFrame(response.data)\n",
                        "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
                        "    df = df.sort_values('datetime')\n",
                        "    print(f'âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {{len(df)}}ê°œ')\n",
                        "    print(f'ğŸ“… ê¸°ê°„: {{df[\"datetime\"].min()}} ~ {{df[\"datetime\"].max()}}')\n",
                        "else:\n",
                        "    print('âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ§® ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°\n",
                        "def calculate_advanced_features(df):\n",
                        "    # ê¸°ë³¸ ì§€í‘œë“¤\n",
                        "    df['sma_5'] = ta.sma(df['close'], length=5)\n",
                        "    df['sma_10'] = ta.sma(df['close'], length=10)\n",
                        "    df['sma_20'] = ta.sma(df['close'], length=20)\n",
                        "    df['ema_9'] = ta.ema(df['close'], length=9)\n",
                        "    df['ema_21'] = ta.ema(df['close'], length=21)\n",
                        "    \n",
                        "    # MACD\n",
                        "    macd = ta.macd(df['close'], fast=6, slow=13, signal=4)\n",
                        "    df['macd'] = macd['MACD_6_13_4']\n",
                        "    df['macd_signal'] = macd['MACDs_6_13_4']\n",
                        "    df['macd_histogram'] = macd['MACDh_6_13_4']\n",
                        "    \n",
                        "    # RSI\n",
                        "    df['rsi'] = ta.rsi(df['close'], length=9)\n",
                        "    df['rsi_14'] = ta.rsi(df['close'], length=14)\n",
                        "    \n",
                        "    # ë³¼ë¦°ì € ë°´ë“œ\n",
                        "    bb = ta.bbands(df['close'], length=10, std=2)\n",
                        "    df['bb_upper'] = bb['BBU_10_2.0']\n",
                        "    df['bb_lower'] = bb['BBL_10_2.0']\n",
                        "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']\n",
                        "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
                        "    \n",
                        "    # ìŠ¤í† ìºìŠ¤í‹±\n",
                        "    stoch = ta.stoch(df['high'], df['low'], df['close'], k=5, d=3)\n",
                        "    df['stoch_k'] = stoch['STOCHk_5_3_3']\n",
                        "    df['stoch_d'] = stoch['STOCHd_5_3_3']\n",
                        "    \n",
                        "    # ATR\n",
                        "    df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=7)\n",
                        "    df['atr_ratio'] = df['atr'] / df['close']\n",
                        "    \n",
                        "    # ADX\n",
                        "    adx = ta.adx(df['high'], df['low'], df['close'], length=7)\n",
                        "    df['adx'] = adx['ADX_7']\n",
                        "    df['di_plus'] = adx['DMP_7']\n",
                        "    df['di_minus'] = adx['DMN_7']\n",
                        "    \n",
                        "    # Williams %R\n",
                        "    df['williams_r'] = ta.willr(df['high'], df['low'], df['close'], length=9)\n",
                        "    \n",
                        "    # Momentum\n",
                        "    df['momentum'] = ta.mom(df['close'], length=10)\n",
                        "    df['momentum_5'] = ta.mom(df['close'], length=5)\n",
                        "    \n",
                        "    # OBV\n",
                        "    df['obv'] = ta.obv(df['close'], df['volume'])\n",
                        "    df['obv_sma'] = ta.sma(df['obv'], length=20)\n",
                        "    \n",
                        "    # CCI\n",
                        "    df['cci'] = ta.cci(df['high'], df['low'], df['close'], length=9)\n",
                        "    \n",
                        "    # Parabolic SAR\n",
                        "    df['psar'] = ta.psar(df['high'], df['low'], df['close'])\n",
                        "    \n",
                        "    # ê°€ê²© ë³€í™”ìœ¨\n",
                        "    df['price_change'] = df['close'].pct_change()\n",
                        "    df['price_change_5'] = df['close'].pct_change(5)\n",
                        "    df['price_change_10'] = df['close'].pct_change(10)\n",
                        "    \n",
                        "    # ë³¼ë¥¨ ì§€í‘œ\n",
                        "    df['volume_sma'] = ta.sma(df['volume'], length=20)\n",
                        "    df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
                        "    \n",
                        "    # ë³€ë™ì„± ì§€í‘œ\n",
                        "    df['volatility'] = df['close'].rolling(20).std()\n",
                        "    df['volatility_ratio'] = df['volatility'] / df['close']\n",
                        "    \n",
                        "    # ì¶”ì„¸ ì§€í‘œ\n",
                        "    df['trend_strength'] = abs(df['ema_9'] - df['ema_21']) / df['close']\n",
                        "    df['trend_direction'] = np.where(df['ema_9'] > df['ema_21'], 1, -1)\n",
                        "    \n",
                        "    # í¬ë¡œìŠ¤ì˜¤ë²„ ì§€í‘œ\n",
                        "    df['ema_cross'] = np.where(df['ema_9'] > df['ema_21'], 1, 0)\n",
                        "    df['ema_cross_change'] = df['ema_cross'].diff()\n",
                        "    \n",
                        "    df['macd_cross'] = np.where(df['macd'] > df['macd_signal'], 1, 0)\n",
                        "    df['macd_cross_change'] = df['macd_cross'].diff()\n",
                        "    \n",
                        "    # ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±\n",
                        "    df['hour'] = df['datetime'].dt.hour\n",
                        "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
                        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
                        "    \n",
                        "    return df\n",
                        "\n",
                        "# ì§€í‘œ ê³„ì‚°\n",
                        "df = calculate_advanced_features(df)\n",
                        "print('âœ… ê³ ê¸‰ ì§€í‘œ ê³„ì‚° ì™„ë£Œ')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ¯ ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
                        "def create_target_variable(df, lookforward=5):\n",
                        "    # ë¯¸ë˜ ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°\n",
                        "    df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1\n",
                        "    \n",
                        "    # ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
                        "    df['target'] = np.where(df['future_return'] > 0.01, 1,  # 1% ì´ìƒ ìƒìŠ¹ ì‹œ LONG\n",
                        "                      np.where(df['future_return'] < -0.01, -1, 0))  # 1% ì´ìƒ í•˜ë½ ì‹œ SHORT\n",
                        "    \n",
                        "    # ì‹ í˜¸ ê°•ë„ ê³„ì‚°\n",
                        "    df['signal_strength'] = abs(df['future_return']) * 100\n",
                        "    \n",
                        "    return df\n",
                        "\n",
                        "# ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
                        "df = create_target_variable(df)\n",
                        "print('âœ… ëª©í‘œ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ')\n",
                        "print(f'ğŸ“Š íƒ€ê²Ÿ ë¶„í¬:\\n{{df[\"target\"].value_counts()}}')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ”§ íŠ¹ì„± ì¤€ë¹„\n",
                        "feature_columns = [\n",
                        "    'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',\n",
                        "    'macd', 'macd_signal', 'macd_histogram',\n",
                        "    'rsi', 'rsi_14',\n",
                        "    'bb_upper', 'bb_lower', 'bb_width', 'bb_position',\n",
                        "    'stoch_k', 'stoch_d',\n",
                        "    'atr', 'atr_ratio',\n",
                        "    'adx', 'di_plus', 'di_minus',\n",
                        "    'williams_r', 'momentum', 'momentum_5',\n",
                        "    'obv', 'obv_sma', 'cci', 'psar',\n",
                        "    'price_change', 'price_change_5', 'price_change_10',\n",
                        "    'volume_ratio', 'volatility_ratio',\n",
                        "    'trend_strength', 'trend_direction',\n",
                        "    'ema_cross', 'ema_cross_change',\n",
                        "    'macd_cross', 'macd_cross_change',\n",
                        "    'hour', 'day_of_week', 'is_weekend'\n",
                        "]\n",
                        "\n",
                        "# NaN ê°’ ì²˜ë¦¬\n",
                        "df = df.dropna()\n",
                        "\n",
                        "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
                        "X = df[feature_columns]\n",
                        "y = df['target']\n",
                        "\n",
                        "print(f'âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ: {{len(feature_columns)}}ê°œ íŠ¹ì„±')\n",
                        "print(f'ğŸ“Š ë°ì´í„° í¬ê¸°: {{X.shape}}')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ¯ ëª¨ë¸ í›ˆë ¨\n",
                        "model_type = '{model_type}'\n",
                        "\n",
                        "# ë°ì´í„° ë¶„í• \n",
                        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                        "\n",
                        "# íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
                        "scaler = StandardScaler()\n",
                        "X_train_scaled = scaler.fit_transform(X_train)\n",
                        "X_test_scaled = scaler.transform(X_test)\n",
                        "\n",
                        "# ë¼ë²¨ ì¸ì½”ë”©\n",
                        "label_encoder = LabelEncoder()\n",
                        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
                        "y_test_encoded = label_encoder.transform(y_test)\n",
                        "\n",
                        "print('âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ')\n",
                        "\n",
                        "# ëª¨ë¸ ì„ íƒ ë° í›ˆë ¨\n",
                        "if model_type == 'random_forest':\n",
                        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                        "elif model_type == 'xgboost':\n",
                        "    model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
                        "elif model_type == 'lightgbm':\n",
                        "    model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
                        "elif model_type == 'lstm':\n",
                        "    # LSTM ëª¨ë¸ì€ ë³„ë„ ì²˜ë¦¬\n",
                        "    pass\n",
                        "else:\n",
                        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                        "\n",
                        "if model_type != 'lstm':\n",
                        "    # ëª¨ë¸ í›ˆë ¨\n",
                        "    model.fit(X_train_scaled, y_train_encoded)\n",
                        "    \n",
                        "    # ì˜ˆì¸¡\n",
                        "    y_pred = model.predict(X_test_scaled)\n",
                        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
                        "    \n",
                        "    print(f'âœ… {{model_type.upper()}} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ')\n",
                        "    print(f'ğŸ“Š ì •í™•ë„: {{accuracy:.4f}}')\n",
                        "    \n",
                        "    # êµì°¨ ê²€ì¦\n",
                        "    cv_scores = cross_val_score(model, X_train_scaled, y_train_encoded, cv=5)\n",
                        "    print(f'ğŸ“Š êµì°¨ ê²€ì¦ í‰ê· : {{cv_scores.mean():.4f}} (Â±{{cv_scores.std():.4f}})')\n",
                        "    \n",
                        "    # ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
                        "    print('\\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:')\n",
                        "    print(classification_report(y_test_encoded, y_pred))"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ§  LSTM ëª¨ë¸ í›ˆë ¨ (LSTMì¸ ê²½ìš°)\n",
                        "if model_type == 'lstm':\n",
                        "    sequence_length = {self.training_config['sequence_length']}\n",
                        "    \n",
                        "    # ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë³€í™˜\n",
                        "    X_sequences = []\n",
                        "    y_sequences = []\n",
                        "    \n",
                        "    for i in range(sequence_length, len(X)):\n",
                        "        X_sequences.append(X.iloc[i-sequence_length:i].values)\n",
                        "        y_sequences.append(y.iloc[i])\n",
                        "    \n",
                        "    X_sequences = np.array(X_sequences)\n",
                        "    y_sequences = np.array(y_sequences)\n",
                        "    \n",
                        "    # ë°ì´í„° ë¶„í• \n",
                        "    split_idx = int(len(X_sequences) * 0.8)\n",
                        "    X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:]\n",
                        "    y_train, y_test = y_sequences[:split_idx], y_sequences[split_idx:]\n",
                        "    \n",
                        "    # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
                        "    scaler = StandardScaler()\n",
                        "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
                        "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
                        "    \n",
                        "    X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
                        "    X_test_scaled = scaler.transform(X_test_reshaped)\n",
                        "    \n",
                        "    X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
                        "    X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
                        "    \n",
                        "    # ë¼ë²¨ ì¸ì½”ë”©\n",
                        "    label_encoder = LabelEncoder()\n",
                        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
                        "    y_test_encoded = label_encoder.transform(y_test)\n",
                        "    \n",
                        "    # ì›-í•« ì¸ì½”ë”©\n",
                        "    y_train_onehot = tf.keras.utils.to_categorical(y_train_encoded, num_classes=3)\n",
                        "    y_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=3)\n",
                        "    \n",
                        "    # LSTM ëª¨ë¸ êµ¬ì¶•\n",
                        "    model = Sequential([\n",
                        "        LSTM(128, return_sequences=True, input_shape=(sequence_length, len(feature_columns))),\n",
                        "        Dropout(0.2),\n",
                        "        LSTM(64, return_sequences=False),\n",
                        "        Dropout(0.2),\n",
                        "        Dense(32, activation='relu'),\n",
                        "        Dropout(0.2),\n",
                        "        Dense(3, activation='softmax')\n",
                        "    ])\n",
                        "    \n",
                        "    model.compile(\n",
                        "        optimizer=Adam(learning_rate=0.001),\n",
                        "        loss='categorical_crossentropy',\n",
                        "        metrics=['accuracy']\n",
                        "    )\n",
                        "    \n",
                        "    # ì½œë°± ì„¤ì •\n",
                        "    callbacks = [\n",
                        "        EarlyStopping(patience=10, restore_best_weights=True),\n",
                        "        ReduceLROnPlateau(factor=0.5, patience=5)\n",
                        "    ]\n",
                        "    \n",
                        "    # ëª¨ë¸ í›ˆë ¨\n",
                        "    history = model.fit(\n",
                        "        X_train_scaled, y_train_onehot,\n",
                        "        validation_data=(X_test_scaled, y_test_onehot),\n",
                        "        epochs={self.training_config['epochs']},\n",
                        "        batch_size={self.training_config['batch_size']},\n",
                        "        callbacks=callbacks,\n",
                        "        verbose=1\n",
                        "    )\n",
                        "    \n",
                        "    # ëª¨ë¸ í‰ê°€\n",
                        "    y_pred = model.predict(X_test_scaled)\n",
                        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
                        "    accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
                        "    \n",
                        "    print(f'âœ… LSTM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ')\n",
                        "    print(f'ğŸ“Š ì •í™•ë„: {{accuracy:.4f}}')\n",
                        "    \n",
                        "    # ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
                        "    print('\\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:')\n",
                        "    print(classification_report(y_test_encoded, y_pred_classes))"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ’¾ ëª¨ë¸ ì €ì¥\n",
                        "import joblib\n",
                        "from google.colab import files\n",
                        "\n",
                        "# ëª¨ë¸ íŒŒì¼ëª…\n",
                        "model_filename = f'{{symbol}}_{{timeframe}}_{{model_type}}_model'\n",
                        "\n",
                        "if model_type == 'lstm':\n",
                        "    # LSTM ëª¨ë¸ ì €ì¥\n",
                        "    model.save(f'{{model_filename}}.h5')\n",
                        "    joblib.dump(scaler, f'{{model_filename}}_scaler.pkl')\n",
                        "    joblib.dump(label_encoder, f'{{model_filename}}_encoder.pkl')\n",
                        "    \n",
                        "    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
                        "    files.download(f'{{model_filename}}.h5')\n",
                        "    files.download(f'{{model_filename}}_scaler.pkl')\n",
                        "    files.download(f'{{model_filename}}_encoder.pkl')\n",
                        "else:\n",
                        "    # ì¼ë°˜ ëª¨ë¸ ì €ì¥\n",
                        "    joblib.dump(model, f'{{model_filename}}.pkl')\n",
                        "    joblib.dump(scaler, f'{{model_filename}}_scaler.pkl')\n",
                        "    joblib.dump(label_encoder, f'{{model_filename}}_encoder.pkl')\n",
                        "    \n",
                        "    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
                        "    files.download(f'{{model_filename}}.pkl')\n",
                        "    files.download(f'{{model_filename}}_scaler.pkl')\n",
                        "    files.download(f'{{model_filename}}_encoder.pkl')\n",
                        "\n",
                        "print('âœ… ëª¨ë¸ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')\n",
                        "print(f'ğŸ“ ì €ì¥ëœ íŒŒì¼: {{model_filename}}')"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# ğŸ“Š í›ˆë ¨ ê²°ê³¼ ìš”ì•½\n",
                        "print('ğŸ‰ í›ˆë ¨ ì™„ë£Œ!')\n",
                        "print(f'ğŸ“ˆ ì‹¬ë³¼: {{symbol.upper()}}')\n",
                        "print(f'â° íƒ€ì„í”„ë ˆì„: {{timeframe}}')\n",
                        "print(f'ğŸ¤– ëª¨ë¸: {{model_type.upper()}}')\n",
                        "print(f'ğŸ“Š ë°ì´í„° í¬ê¸°: {{len(df)}}ê°œ')\n",
                        "print(f'ğŸ”§ íŠ¹ì„± ìˆ˜: {{len(feature_columns)}}ê°œ')\n",
                        "\n",
                        "if model_type != 'lstm':\n",
                        "    print(f'ğŸ¯ ì •í™•ë„: {{accuracy:.4f}}')\n",
                        "    print(f'ğŸ“Š êµì°¨ ê²€ì¦: {{cv_scores.mean():.4f}} (Â±{{cv_scores.std():.4f}})')\n",
                        "else:\n",
                        "    print(f'ğŸ¯ ì •í™•ë„: {{accuracy:.4f}}')\n",
                        "\n",
                        "print('\\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:')\n",
                        "print('1. ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ íŒŒì¼ì„ ë¡œì»¬ë¡œ ì´ë™')\n",
                        "print('2. ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì— ëª¨ë¸ ë¡œë“œ')\n",
                        "print('3. ë°±í…ŒìŠ¤íŒ…ìœ¼ë¡œ ì„±ëŠ¥ ê²€ì¦')\n",
                        "print('4. ì‹¤ì‹œê°„ ì‹ í˜¸ ìƒì„± ì‹œì‘')"
                    ]
                }
            ],
            "metadata": {
                "kernelspec": {
                    "display_name": "Python 3",
                    "language": "python",
                    "name": "python3"
                },
                "language_info": {
                    "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                    },
                    "file_extension": ".py",
                    "mimetype": "text/x-python",
                    "name": "python",
                    "nbconvert_exporter": "python",
                    "pygments_lexer": "ipython3",
                    "version": "3.8.5"
                }
            },
            "nbformat": 4,
            "nbformat_minor": 4
        }
        
        return json.dumps(notebook_template, indent=2)
    
    def upload_to_colab(self, notebook_file):
        """Colabì— ë…¸íŠ¸ë¶ ì—…ë¡œë“œ"""
        try:
            logging.info(f"ğŸ“¤ Colabì— ë…¸íŠ¸ë¶ ì—…ë¡œë“œ ì¤‘: {notebook_file}")
            
            # ë…¸íŠ¸ë¶ íŒŒì¼ ì½ê¸°
            with open(notebook_file, 'r', encoding='utf-8') as f:
                notebook_content = f.read()
            
            # Colab APIë¥¼ í†µí•œ ì—…ë¡œë“œ (ì‹¤ì œ êµ¬í˜„ì€ ë³µì¡í•˜ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜)
            logging.info("âœ… ë…¸íŠ¸ë¶ ì—…ë¡œë“œ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)")
            
            # ì‹¤ì œë¡œëŠ” Google Drive APIë‚˜ Colab APIë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
            return True
            
        except Exception as e:
            logging.error(f"âŒ Colab ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def run_colab_training(self, symbol, timeframe, model_type):
        """Colabì—ì„œ ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰"""
        try:
            logging.info(f"ğŸš€ {symbol} {timeframe} {model_type} Colab í›ˆë ¨ ì‹œì‘...")
            
            # 1. ë…¸íŠ¸ë¶ ìƒì„±
            notebook_file = self.prepare_colab_notebook(symbol, timeframe, model_type)
            if not notebook_file:
                return False
            
            # 2. Colabì— ì—…ë¡œë“œ
            if not self.upload_to_colab(notebook_file):
                return False
            
            # 3. í›ˆë ¨ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
            logging.info("ğŸ”„ Colabì—ì„œ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            time.sleep(5)  # ì‹¤ì œë¡œëŠ” í›ˆë ¨ ì‹œê°„ë§Œí¼ ëŒ€ê¸°
            
            # 4. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)
            logging.info("ğŸ“¥ í›ˆë ¨ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            model_filename = f"{symbol}_{timeframe}_{model_type}_model"
            
            # ì‹¤ì œë¡œëŠ” Colabì—ì„œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬
            logging.info(f"âœ… {model_type} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            logging.info(f"ğŸ“ ëª¨ë¸ íŒŒì¼: {model_filename}")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ Colab í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def train_all_models_colab(self):
        """ëª¨ë“  ëª¨ë¸ì„ Colabì—ì„œ í›ˆë ¨"""
        logging.info("ğŸš€ Colab ì „ì²´ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        success_count = 0
        total_count = len(self.training_config['symbols']) * len(self.training_config['timeframes']) * len(self.training_config['models'])
        
        for symbol in self.training_config['symbols']:
            for timeframe in self.training_config['timeframes']:
                for model_type in self.training_config['models']:
                    try:
                        logging.info(f"ğŸ”„ {symbol} {timeframe} {model_type} í›ˆë ¨ ì¤‘...")
                        
                        if self.run_colab_training(symbol, timeframe, model_type):
                            success_count += 1
                            logging.info(f"âœ… {symbol} {timeframe} {model_type} í›ˆë ¨ ì„±ê³µ!")
                        else:
                            logging.error(f"âŒ {symbol} {timeframe} {model_type} í›ˆë ¨ ì‹¤íŒ¨!")
                        
                        # í›ˆë ¨ ê°„ê²©
                        time.sleep(2)
                        
                    except Exception as e:
                        logging.error(f"âŒ {symbol} {timeframe} {model_type} í›ˆë ¨ ì˜¤ë¥˜: {str(e)}")
        
        logging.info(f"ğŸ‰ Colab í›ˆë ¨ ì™„ë£Œ! ì„±ê³µ: {success_count}/{total_count}")
        
        return success_count, total_count
    
    def generate_training_report(self):
        """í›ˆë ¨ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'training_config': self.training_config,
                'models_trained': [],
                'performance_summary': {}
            }
            
            # ëª¨ë¸ íŒŒì¼ í™•ì¸
            for symbol in self.training_config['symbols']:
                for timeframe in self.training_config['timeframes']:
                    for model_type in self.training_config['models']:
                        model_filename = f"{symbol}_{timeframe}_{model_type}_model"
                        
                        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                        model_files = list(self.model_path.glob(f"{model_filename}*"))
                        
                        if model_files:
                            report['models_trained'].append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'model_type': model_type,
                                'files': [f.name for f in model_files]
                            })
            
            # ë¦¬í¬íŠ¸ ì €ì¥
            report_file = self.model_path / 'training_report.json'
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logging.info(f"ğŸ“Š í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_file}")
            
            return report
            
        except Exception as e:
            logging.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def start(self):
        """Colab í›ˆë ¨ ì‹œìŠ¤í…œ ì‹œì‘"""
        logging.info("ğŸš€ Colab ê¸°ë°˜ ML ëª¨ë¸ í›ˆë ¨ ì‹œìŠ¤í…œ ì‹œì‘...")
        
        try:
            # ì „ì²´ ëª¨ë¸ í›ˆë ¨
            success_count, total_count = self.train_all_models_colab()
            
            # í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„±
            report = self.generate_training_report()
            
            logging.info("ğŸ‰ Colab í›ˆë ¨ ì‹œìŠ¤í…œ ì™„ë£Œ!")
            logging.info(f"ğŸ“Š í›ˆë ¨ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")
            
            if report:
                logging.info(f"ğŸ“‹ í›ˆë ¨ëœ ëª¨ë¸: {len(report['models_trained'])}ê°œ")
            
        except KeyboardInterrupt:
            logging.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logging.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Google Colab ê¸°ë°˜ ML ëª¨ë¸ í›ˆë ¨ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        colab_system = ColabTrainingSystem()
        colab_system.start()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
