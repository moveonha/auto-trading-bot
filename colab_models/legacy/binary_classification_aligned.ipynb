{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ (ë°ì´í„° ì •ë ¬ ë¬¸ì œ í•´ê²°)\n",
        "\n",
        "## ğŸ“Š í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°:\n",
        "## 1. 3í´ë˜ìŠ¤ â†’ 2í´ë˜ìŠ¤ë¡œ ë‹¨ìˆœí™”\n",
        "## 2. ì„ê³„ê°’ 0.2%ë¡œ ë‚®ì¶¤\n",
        "## 3. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
        "## 4. ë°ì´í„° ì •ë ¬ ë¬¸ì œ í•´ê²°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "%pip install pandas==2.0.3 numpy==1.24.3 scikit-learn==1.3.0 xgboost==1.7.6 lightgbm==4.0.0 tensorflow==2.13.0 pandas-ta==0.3.14b0 supabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade pip",
        "!pip install xgboost lightgbm pandas-ta supabase plotly numba",
        "",
        "# ğŸ”§ NumPy 2.0 í˜¸í™˜ì„± íŒ¨ì¹˜ (ì¦‰ì‹œ í•´ê²°!)",
        "import numpy as np",
        "if not hasattr(np, 'NaN'):",
        "    np.NaN = np.nan",
        "    print(\"âœ… NumPy íŒ¨ì¹˜ ì ìš© ì™„ë£Œ!\")",
        "",
        "# ì´ì œ pandas_ta ì •ìƒ ë™ì‘",
        "import pandas_ta as ta",
        "print(\"âœ… pandas_ta ì„í¬íŠ¸ ì„±ê³µ!\")",
        "print(f\"ë²„ì „: {ta.version}\")",
        "",
        "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸",
        "import pandas as pd",
        "from sklearn.ensemble import RandomForestClassifier",
        "from sklearn.model_selection import train_test_split, cross_val_score",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix",
        "import lightgbm as lgb",
        "from supabase import create_client",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "print('âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”— Supabase ì—°ê²°\n",
        "SUPABASE_URL = \"https://your-project.supabase.co\"\n",
        "SUPABASE_KEY = \"your-anon-key\"\n",
        "\n",
        "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "print('âœ… Supabase ì—°ê²° ì™„ë£Œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ (ë°°ì¹˜ ì²˜ë¦¬)\n",
        "def collect_data_in_batches(symbol='ADAUSDT', timeframe='1m', target_records=500000):\n",
        "    \"\"\"ë°°ì¹˜ë¡œ ë°ì´í„° ìˆ˜ì§‘\"\"\"\n",
        "    all_data = []\n",
        "    offset = 0\n",
        "    batch_size = 1000\n",
        "    \n",
        "    print(f'ğŸ”„ {symbol} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...')\n",
        "    \n",
        "    while len(all_data) < target_records:\n",
        "        try:\n",
        "            response = supabase.table('crypto_ohlcv').select('*').eq('symbol', symbol).eq('timeframe', timeframe).order('timestamp', desc=True).range(offset, offset + batch_size - 1).execute()\n",
        "            \n",
        "            if not response.data:\n",
        "                break\n",
        "                \n",
        "            all_data.extend(response.data)\n",
        "            offset += batch_size\n",
        "            \n",
        "            if len(all_data) % 10000 == 0:\n",
        "                print(f'ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°: {len(all_data):,}ê°œ')\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f'âŒ ë°°ì¹˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}')\n",
        "            break\n",
        "    \n",
        "    print(f'âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data):,}ê°œ')\n",
        "    return all_data\n",
        "\n",
        "# ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰\n",
        "raw_data = collect_data_in_batches()\n",
        "\n",
        "# DataFrame ìƒì„±\n",
        "df = pd.DataFrame(raw_data)\n",
        "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "df = df.sort_values('datetime')\n",
        "\n",
        "print(f'ğŸ“… ê¸°ê°„: {df[\"datetime\"].min()} ~ {df[\"datetime\"].max()}')\n",
        "print(f'ğŸ“Š ì´ ë°ì´í„°: {len(df):,}ê°œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°\"\"\"\n",
        "    # ì´ë™í‰ê· \n",
        "    df['sma_5'] = ta.sma(df['close'], length=5)\n",
        "    df['sma_10'] = ta.sma(df['close'], length=10)\n",
        "    df['sma_20'] = ta.sma(df['close'], length=20)\n",
        "    df['ema_9'] = ta.ema(df['close'], length=9)\n",
        "    df['ema_21'] = ta.ema(df['close'], length=21)\n",
        "    \n",
        "    # MACD\n",
        "    macd = ta.macd(df['close'])\n",
        "    df['macd'] = macd['MACD_12_26_9']\n",
        "    df['macd_signal'] = macd['MACDs_12_26_9']\n",
        "    df['macd_histogram'] = macd['MACDh_12_26_9']\n",
        "    \n",
        "    # RSI\n",
        "    df['rsi'] = ta.rsi(df['close'], length=14)\n",
        "    \n",
        "    # ë³¼ë¦°ì € ë°´ë“œ\n",
        "    bb = ta.bbands(df['close'])\n",
        "    df['bb_upper'] = bb['BBU_20_2.0']\n",
        "    df['bb_lower'] = bb['BBL_20_2.0']\n",
        "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']\n",
        "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
        "    \n",
        "    # ê°€ê²© ë³€í™”ìœ¨\n",
        "    df['price_change'] = df['close'].pct_change()\n",
        "    df['price_change_5'] = df['close'].pct_change(5)\n",
        "    df['price_change_10'] = df['close'].pct_change(10)\n",
        "    \n",
        "    # ê±°ë˜ëŸ‰ ì§€í‘œ\n",
        "    df['volume_sma'] = ta.sma(df['volume'], length=20)\n",
        "    df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
        "    \n",
        "    # ì‹œê°„ íŠ¹ì„±\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ì§€í‘œ ê³„ì‚°\n",
        "df = calculate_technical_indicators(df)\n",
        "print('âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ ì´ì§„ ë¶„ë¥˜ ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
        "def create_binary_target(df, lookforward=5, threshold=0.002):  # 0.2% ì„ê³„ê°’\n",
        "    # ë¯¸ë˜ ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°\n",
        "    df['future_return'] = df['close'].shift(-lookforward) / df['close'] - 1\n",
        "    \n",
        "    # ì´ì§„ ë¶„ë¥˜: ìƒìŠ¹(1) vs í•˜ë½(0)\n",
        "    df['target'] = np.where(df['future_return'] > threshold, 1, 0)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ëª©í‘œ ë³€ìˆ˜ ìƒì„±\n",
        "df = create_binary_target(df)\n",
        "print('âœ… ì´ì§„ ë¶„ë¥˜ ëª©í‘œ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ')\n",
        "print(f'ğŸ“Š íƒ€ê²Ÿ ë¶„í¬:\\n{df[\"target\"].value_counts()}')\n",
        "print(f'ğŸ“ˆ ìƒìŠ¹ ë¹„ìœ¨: {df[\"target\"].mean()*100:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”§ ë°ì´í„° ì •ë ¬ ë° ì „ì²˜ë¦¬ (ì¤‘ìš”!)\n",
        "feature_columns = [\n",
        "    'sma_5', 'sma_10', 'sma_20', 'ema_9', 'ema_21',\n",
        "    'macd', 'macd_signal', 'macd_histogram',\n",
        "    'rsi',\n",
        "    'bb_upper', 'bb_lower', 'bb_width', 'bb_position',\n",
        "    'price_change', 'price_change_5', 'price_change_10',\n",
        "    'volume_sma', 'volume_ratio',\n",
        "    'hour', 'day_of_week', 'is_weekend'\n",
        "]\n",
        "\n",
        "# ëª¨ë“  íŠ¹ì„±ê³¼ íƒ€ê²Ÿì´ ìˆëŠ” í–‰ë§Œ ì„ íƒ\n",
        "all_columns = feature_columns + ['target']\n",
        "df_clean = df[all_columns].dropna()\n",
        "\n",
        "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
        "X = df_clean[feature_columns]\n",
        "y = df_clean['target']\n",
        "\n",
        "print(f'ğŸ”§ ë°ì´í„° ì •ë ¬ ì™„ë£Œ')\n",
        "print(f'ğŸ“Š íŠ¹ì„± ë°ì´í„°: {X.shape}')\n",
        "print(f'ğŸ“Š íƒ€ê²Ÿ ë°ì´í„°: {y.shape}')\n",
        "print(f'âœ… ìƒ˜í”Œ ìˆ˜ ì¼ì¹˜: {X.shape[0] == y.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ ì´ì§„ ë¶„ë¥˜ LightGBM ëª¨ë¸\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# ë°ì´í„° ë¶„í• \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
        "class_weights = {0: 1, 1: 5}  # ìƒìŠ¹ì— 5ë°° ê°€ì¤‘ì¹˜\n",
        "\n",
        "# LightGBM ëª¨ë¸ ì„¤ì •\n",
        "model = lgb.LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=8,\n",
        "    num_leaves=31,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "print('ğŸš€ ì´ì§„ ë¶„ë¥˜ LightGBM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...')\n",
        "print(f'ğŸ“Š í›ˆë ¨ ë°ì´í„°: {X_train.shape}')\n",
        "print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}')\n",
        "print(f'âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}')\n",
        "\n",
        "# ëª¨ë¸ í›ˆë ¨\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ')\n",
        "print(f'ğŸ“Š ì •í™•ë„: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# êµì°¨ ê²€ì¦\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print('ğŸ“Š êµì°¨ ê²€ì¦ ê²°ê³¼:')\n",
        "print(f'í‰ê·  ì •í™•ë„: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})')\n",
        "print(f'ê°œë³„ ì •í™•ë„: {cv_scores}')\n",
        "\n",
        "# ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
        "print('\\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬\n",
        "print('\\nğŸ“Š í˜¼ë™ í–‰ë ¬:')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# íŠ¹ì„± ì¤‘ìš”ë„\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print('\\nğŸ† ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:')\n",
        "print(feature_importance.head(10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}